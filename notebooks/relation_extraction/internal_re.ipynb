{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "plastic-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regulation-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\\\\parser\")\n",
    "import internal_parser\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "owned-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "simple-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "competent-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NUM_CLASSES = 8 # Number of relation classes\n",
    "NUM_EPOCH = 50\n",
    "MAX_TOKEN = 128 # Max tokens in each sentence, set to 128 for limited RAM capacity\n",
    "VALIDATION_SIZE = 1000 # Number of observations evalutated in validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "distinguished-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surgical-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(group):\n",
    "    docs = internal_parser.get_docs(group)\n",
    "    data = internal_parser.extract_data(docs)\n",
    "    for doc in data:\n",
    "        sentence_id = 0\n",
    "        starting_index = 0\n",
    "        input_ids = []\n",
    "        # ddd a final row with dummy sentence embedding\n",
    "        doc[\"data_frame\"].loc[doc[\"data_frame\"].index.max() + 1, \"sentence_embedding\"] \\\n",
    "            = doc[\"data_frame\"][\"sentence_embedding\"].max() + 1\n",
    "        for index, row in doc[\"data_frame\"].iterrows():\n",
    "            if row[\"sentence_embedding\"] != sentence_id or index - starting_index >= MAX_TOKEN - 2:\n",
    "                new_entity_position = {}\n",
    "                for entity in doc[\"entity_position\"]:\n",
    "                    if starting_index <= doc[\"entity_position\"][entity][0] < doc[\"entity_position\"][entity][1] <= index:\n",
    "                        new_entity_position[entity] = (\n",
    "                            doc[\"entity_position\"][entity][0] - starting_index + 1, # +1: space for CLS token\n",
    "                            doc[\"entity_position\"][entity][1] - starting_index + 1  # +1: space for CLS token\n",
    "                        )\n",
    "                        \n",
    "                # If this sentence has at least two entities for a possible relation\n",
    "                if len(new_entity_position) >= 2:\n",
    "                    # Add CLS and SEP to the sentence\n",
    "                    input_ids = [internal_parser.CLS_TOKEN] + input_ids + [internal_parser.SEP_TOKEN]\n",
    "                    e1_mask, e2_mask, labels = model.generate_entity_mask(len(input_ids), new_entity_position, doc[\"relations\"])\n",
    "                    assert e1_mask.shape[0] == e2_mask.shape[0] == labels.shape[0]\n",
    "                    assert len(input_ids) == e1_mask.shape[1] == e2_mask.shape[1]\n",
    "                    yield {\n",
    "                        \"input_ids\": torch.tensor([input_ids]).long(),# .to(device), \n",
    "                        \"attention_mask\": torch.ones((1, len(input_ids)), dtype=torch.long),# .to(device),\n",
    "                        \"token_type_ids\": torch.zeros((1, len(input_ids)), dtype=torch.long),# .to(device),\n",
    "                        \"e1_mask\": e1_mask,# .to(device),\n",
    "                        \"e2_mask\": e2_mask,# .to(device),\n",
    "                        \"labels\": labels# .to(device)\n",
    "                    }\n",
    "                    del e1_mask\n",
    "                    del e2_mask\n",
    "                    del labels\n",
    "                    \n",
    "                sentence_id = row[\"sentence_embedding\"]\n",
    "                input_ids = []\n",
    "                starting_index = index\n",
    "            \n",
    "            input_ids.append(row[\"token_ids\"])   \n",
    "        \n",
    "        del input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abstract-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test data_generator()\n",
    "# generator = data_generator(\"All\")\n",
    "# # Test on the first document (\"143f9e00-34c4-11eb-a28a-8b07c9b15060-0\")\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 1015\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 2057\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 2119\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 2012\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 5214\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 1016\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 2057\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 8115\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 4550\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 1999\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 1016\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 2009\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 2057\n",
    "# assert next(generator)[\"input_ids\"][0, 1] == 2156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "outside-release",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMre(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1536, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mre_model = model.BertForMre(NUM_CLASSES)\n",
    "mre_model.load_state_dict(torch.load(\"../model/re/internal_50.model\", map_location=torch.device('cpu')))\n",
    "mre_model.eval() # Set model for evaluation only\n",
    "# mre_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "welcome-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except for the last classifier layer on top\n",
    "for param in mre_model.parameters():\n",
    "    param.requires_grad = False\n",
    "mre_model.classifier.weight.requires_grad = True\n",
    "mre_model.classifier.bias.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "residential-surname",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: torch.Size([30522, 768])\n",
      "False\n",
      "size: torch.Size([512, 768])\n",
      "False\n",
      "size: torch.Size([2, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([8, 1536])\n",
      "True\n",
      "size: torch.Size([8])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in mre_model.parameters():\n",
    "    print(\"size:\", param.shape)\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "shared-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "optimizer = AdamW(mre_model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tropical-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(count):\n",
    "    val_generator = data_generator(\"Test\")\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    for i in range(count):\n",
    "        inputs = next(val_generator)\n",
    "        # forward\n",
    "        outputs = mre_model(**inputs)\n",
    "        true_labels += inputs[\"labels\"].tolist()\n",
    "        pred_labels = F.softmax(outputs.logits, dim=-1).argmax(dim=1)\n",
    "        predicted_labels += pred_labels.tolist()\n",
    "        assert len(predicted_labels) == len(true_labels)\n",
    "        del inputs\n",
    "        \n",
    "    print(\"[validation %d]\" % (count))\n",
    "    result = pd.DataFrame(columns=[\"precision\", \"recall\", \"fbeta_score\", \"support\"])\n",
    "    result.loc[\"macro\"] = list(precision_recall_fscore_support(true_labels, predicted_labels, average=\"macro\"))\n",
    "    result.loc[\"micro\"] = list(precision_recall_fscore_support(true_labels, predicted_labels, average=\"micro\"))\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wicked-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for epoch in range(NUM_EPOCH):  # loop over the dataset multiple times\n",
    "        true_labels = []\n",
    "        predicted_labels = []\n",
    "\n",
    "        for i, inputs in enumerate(data_generator(\"Training\"), 0):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = mre_model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            true_labels += inputs[\"labels\"].tolist()\n",
    "            pred_labels = F.softmax(outputs.logits, dim=-1).argmax(dim=1)\n",
    "            predicted_labels += pred_labels.tolist()\n",
    "            assert len(predicted_labels) == len(true_labels)\n",
    "            if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "                print(\"[%d, %5d]\" % (epoch + 1, i + 1))\n",
    "                result = pd.DataFrame(columns=[\"precision\", \"recall\", \"fbeta_score\", \"support\"])\n",
    "                result.loc[\"macro\"] = list(precision_recall_fscore_support(true_labels, predicted_labels, average=\"macro\"))\n",
    "                result.loc[\"micro\"] = list(precision_recall_fscore_support(true_labels, predicted_labels, average=\"micro\"))\n",
    "                print(result)\n",
    "                true_labels = []\n",
    "                predicted_labels = []\n",
    "                \n",
    "            del inputs\n",
    "            \n",
    "        validate_model(VALIDATION_SIZE)\n",
    "        \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "directed-watson",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mathematical-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    test_generator = data_generator(\"Test\")\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    for inputs in test_generator:\n",
    "        # forward\n",
    "        outputs = mre_model(**inputs)\n",
    "        true_labels += inputs[\"labels\"].tolist()\n",
    "        pred_labels = F.softmax(outputs.logits, dim=-1).argmax(dim=1)\n",
    "        predicted_labels += pred_labels.tolist()\n",
    "        assert len(predicted_labels) == len(true_labels)\n",
    "        del inputs\n",
    "    \n",
    "    label_map = {v: k for k, v in internal_parser.relation_encode.items()}\n",
    "    classes = list(label_map.keys())\n",
    "    precision, recall, fbeta_score, support = precision_recall_fscore_support(true_labels, predicted_labels, average=None, labels=classes)\n",
    "    result = pd.DataFrame(index=[label_map[c] for c in classes])\n",
    "    result[\"precision\"] = precision\n",
    "    result[\"recall\"] = recall\n",
    "    result[\"fbeta_score\"] = fbeta_score\n",
    "    result[\"support\"] = support\n",
    "    result.loc[\"macro\"] = list(precision_recall_fscore_support(true_labels, predicted_labels, average=\"macro\"))\n",
    "    result.loc[\"micro\"] = list(precision_recall_fscore_support(true_labels, predicted_labels, average=\"micro\"))\n",
    "    \n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sapphire-victim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  fbeta_score  support\n",
      "None           0.974049  0.981836     0.977927  23893.0\n",
      "Makes          0.679907  0.653933     0.666667    445.0\n",
      "Of             0.501818  0.415038     0.454321    665.0\n",
      "IsRelatedTo    0.825581  0.554688     0.663551    128.0\n",
      "HasActivity    0.500000  0.714286     0.588235      7.0\n",
      "Recognizes     0.750000  0.321429     0.450000     28.0\n",
      "In             0.000000  0.000000     0.000000      4.0\n",
      "IsInvolvedIn   0.000000  0.000000     0.000000      0.0\n",
      "macro          0.604479  0.520173     0.542957      NaN\n",
      "micro          0.957926  0.957926     0.957926      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "result = test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_csv(\"internal_50_train+test_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(mre_model.state_dict(), \"../model/re/internal_100.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-theology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

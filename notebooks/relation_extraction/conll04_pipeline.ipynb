{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "administrative-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "according-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../parser\")\n",
    "sys.path.append(\"../spert\")\n",
    "import conll04_parser as parser\n",
    "import evaluator\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accomplished-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_bio = {v: k for k, v in parser.entity_encode.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "touched-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_label_map = {(v+1)//2: k for k, v in parser.entity_encode.items()}\n",
    "entity_classes = list(entity_label_map.keys())\n",
    "entity_classes.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "union-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_label_map = {v: k for k, v in parser.relation_encode.items()}\n",
    "relation_classes = list(relation_label_map.keys())\n",
    "relation_classes.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "overhead-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "synthetic-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pressed-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "affiliated-uncle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading entity recognition model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading entity recognition model...\")\n",
    "ner_model = pickle.load(open(\"../../model/ner/conll04_nn_1024.model\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "northern-restaurant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading relation extraction model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMre(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1536, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading relation extraction model...\")\n",
    "re_model = model.BertForMre(len(relation_classes)+1)\n",
    "re_model.load_state_dict(torch.load(\"../../model/re/conll04_100.model\", map_location=device))\n",
    "re_model.eval() # Set model for evaluation only\n",
    "re_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "recognized-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_doc(\n",
    "    document, \n",
    "    pretrain_model, \n",
    "    ignore_index=CrossEntropyLoss().ignore_index,\n",
    "    cls_token=parser.CLS_TOKEN,\n",
    "    sep_token=parser.SEP_TOKEN\n",
    "):\n",
    "    \"\"\"Transform a parsed document with a pre-trained model (BERT)\n",
    "    Only the first token of each word is labeled, the others are masked as 'ignore_index'\n",
    "    The label is in the original BIO format\n",
    "    \"\"\"\n",
    "    ids = document[\"data_frame\"][\"ids\"].tolist()\n",
    "    tokens = document[\"data_frame\"][\"token_ids\"].tolist()\n",
    "    labels = document[\"data_frame\"][\"entity_embedding\"].tolist()\n",
    "    words = document[\"data_frame\"][\"words\"].tolist()\n",
    "        \n",
    "    for i in range(len(tokens)):\n",
    "        if i > 0 and ids[i] == ids[i-1]:\n",
    "            # Extra tokens from the same word are ignored\n",
    "            labels[i] = ignore_index\n",
    "                   \n",
    "    tokens = [cls_token] + tokens\n",
    "    tokens.append(sep_token)\n",
    "    \n",
    "    outputs = pretrain_model(\n",
    "        input_ids=torch.tensor([tokens]), \n",
    "        token_type_ids=torch.tensor([[0] * len(tokens)]),\n",
    "        attention_mask=torch.tensor([[1] * len(tokens)])\n",
    "    )\n",
    "    transformed_tokens = outputs.last_hidden_state[0, 1:-1].tolist()\n",
    "            \n",
    "    assert len(transformed_tokens) == len(labels) == len(words)\n",
    "    return pd.DataFrame(transformed_tokens), pd.DataFrame(list(zip(labels, words)), columns=[\"labels\", \"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "decent-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test transform docs\n",
    "rawdata = parser.extract_data(\"test\")\n",
    "doc0 = rawdata[0]\n",
    "token_df0, label_df0 = transform_doc(doc0, bert_model)\n",
    "assert token_df0.shape[0] == label_df0.shape[0]\n",
    "assert token_df0.shape[1] == 768\n",
    "assert label_df0.shape[1] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "decimal-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entity(ner_model, tokens, labels, \n",
    "                   ignore_index=CrossEntropyLoss().ignore_index):\n",
    "    \"\"\"Given a document, runs entity recognition, returns the predicted entity embedding and spans\"\"\"\n",
    "    true_entity_embedding = np.zeros(tokens.shape[0])\n",
    "    pred_entity_embedding = np.zeros(tokens.shape[0])\n",
    "    true_entity_span = []\n",
    "    pred_entity_span = []\n",
    "    true_entity_span_lock = True\n",
    "    pred_entity_span_lock = True\n",
    "    \n",
    "    test_tokens = tokens[labels[\"labels\"] != ignore_index]\n",
    "    pred_labels = ner_model.predict(test_tokens)\n",
    "    \n",
    "    j = -1\n",
    "    true_label = None\n",
    "    pred_label = None\n",
    "    for i in range(tokens.shape[0]):\n",
    "        if labels.at[i, \"labels\"] != ignore_index:\n",
    "            j += 1\n",
    "            true_label = labels.at[i, \"labels\"]\n",
    "            pred_label = pred_labels[j]\n",
    "            \n",
    "            true_entity_type = label_map_bio[true_label]\n",
    "            if true_entity_type.startswith(\"B\") or (true_entity_type.startswith(\"I\") and true_entity_span_lock):\n",
    "                true_entity_span.append((i, i + 1, (true_label+1)//2))\n",
    "                true_entity_span_lock = False\n",
    "            elif true_entity_type == \"O\":\n",
    "                true_entity_span_lock = True\n",
    "                \n",
    "            pred_entity_type = label_map_bio[pred_label]\n",
    "            if pred_entity_type.startswith(\"B\") or (pred_entity_type.startswith(\"I\") and pred_entity_span_lock):\n",
    "                pred_entity_span.append((i, i + 1, (pred_label+1)//2))\n",
    "                pred_entity_span_lock = False\n",
    "            elif pred_entity_type == \"O\":\n",
    "                pred_entity_span_lock = True\n",
    "            \n",
    "            true_entity_embedding[i] = true_label\n",
    "            pred_entity_embedding[i] = pred_label\n",
    "                \n",
    "        if not true_entity_span_lock:\n",
    "            if (true_label+1)//2 != true_entity_span[-1][2]:\n",
    "                true_entity_span.append((i, i + 1, (true_label+1)//2))\n",
    "            else:\n",
    "                true_entity_span[-1] = (true_entity_span[-1][0], i + 1, (true_label+1)//2)\n",
    "                \n",
    "        if not pred_entity_span_lock:\n",
    "            if (pred_label+1)//2 != pred_entity_span[-1][2]:\n",
    "                pred_entity_span.append((i, i + 1, (pred_label+1)//2))\n",
    "            else:\n",
    "                pred_entity_span[-1] = (pred_entity_span[-1][0], i + 1, (pred_label+1)//2)\n",
    "    \n",
    "    return (true_entity_embedding+1)//2, (pred_entity_embedding+1)//2, true_entity_span, pred_entity_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "interested-departure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 2. 0. 0. 0. 0. 0. 0. 4. 4. 0. 0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 4.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] [0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 4. 3. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 2.\n",
      " 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] [(1, 2, 4), (10, 12, 3), (13, 14, 1), (15, 16, 2), (23, 26, 2), (32, 39, 4), (47, 49, 4), (55, 56, 1)] [(1, 2, 4), (10, 11, 4), (11, 12, 3), (13, 14, 1), (15, 16, 2), (23, 26, 2), (55, 56, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Test entity recognition\n",
    "true_entity_embedding, pred_entity_embedding, true_entity_span, pred_entity_span \\\n",
    "    = predict_entity(ner_model, token_df0, label_df0)\n",
    "print(true_entity_embedding, pred_entity_embedding, true_entity_span, pred_entity_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "everyday-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_relation_span(doc):\n",
    "    true_relation_span = []\n",
    "    for relation in doc[\"relations\"]:\n",
    "        source = doc[\"relations\"][relation][\"source\"]\n",
    "        target = doc[\"relations\"][relation][\"target\"]\n",
    "        relation_type = doc[\"relations\"][relation][\"type\"]\n",
    "        \n",
    "        e1_begin = doc[\"entity_position\"][source][0]\n",
    "        e1_end = doc[\"entity_position\"][source][1]\n",
    "        e1_type = doc[\"data_frame\"].at[e1_begin, \"entity_embedding\"]\n",
    "        \n",
    "        e2_begin = doc[\"entity_position\"][target][0]\n",
    "        e2_end = doc[\"entity_position\"][target][1]\n",
    "        e2_type = doc[\"data_frame\"].at[e2_begin, \"entity_embedding\"]\n",
    "        \n",
    "        true_relation_span.append(((e1_begin, e1_end, e1_type),\n",
    "                                   (e2_begin, e2_end, e2_type), \n",
    "                                   relation_type))\n",
    "    return true_relation_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "instructional-acrobat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((23, 26, 3), (15, 16, 3), 1)]\n"
     ]
    }
   ],
   "source": [
    "# Test get_true_relation_span()\n",
    "true_relation_span = get_true_relation_span(doc0)\n",
    "assert len(doc0[\"relations\"]) == len(true_relation_span)\n",
    "print(true_relation_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "under-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_entity_mask(sentence_length, entity_span, offset=-1):\n",
    "    e1_mask = []\n",
    "    e2_mask = []\n",
    "    candidate_relation_span = []\n",
    "    for e1 in entity_span:\n",
    "        for e2 in entity_span:\n",
    "            if e1 != e2:\n",
    "                template = [0] * sentence_length\n",
    "                template[e1[0]: e1[1]] = [1] * (e1[1] - e1[0])\n",
    "                e1_mask.append(template)\n",
    "                \n",
    "                template = [0] * sentence_length\n",
    "                template[e2[0]: e2[1]] = [1] * (e2[1] - e2[0])\n",
    "                e2_mask.append(template)\n",
    "                \n",
    "                candidate_relation_span.append(((e1[0] + offset, e1[1] + offset, e1[2]), \n",
    "                                                (e2[0] + offset, e2[1] + offset, e2[2])))\n",
    "    # print(e1_mask, e2_mask, candidate_relation_span)\n",
    "    return torch.tensor(e1_mask, dtype=torch.long), torch.tensor(e2_mask, dtype=torch.long), candidate_relation_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "crucial-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_doc(doc, pred_entity_span, max_entity_pair=1000):\n",
    "    \"\"\"Prepare inputs for the relation extraction\"\"\"\n",
    "    # If this sentence has at least two entities for a possible relation\n",
    "    if len(pred_entity_span) >= 2:\n",
    "        offset = -1\n",
    "        new_entity_span = []\n",
    "        for entity in pred_entity_span:\n",
    "            new_entity_span.append((entity[0] - offset, \n",
    "                                    entity[1] - offset, \n",
    "                                    entity[2]))\n",
    "        # Add CLS and SEP to the sentence\n",
    "        input_ids = [parser.CLS_TOKEN] + doc[\"data_frame\"][\"token_ids\"].tolist() + [parser.SEP_TOKEN]\n",
    "        e1_mask, e2_mask, candidate_relation_span = generate_entity_mask(len(input_ids), new_entity_span, offset)\n",
    "        assert e1_mask.shape[0] == e2_mask.shape[0] == len(candidate_relation_span)\n",
    "        assert len(input_ids) == e1_mask.shape[1] == e2_mask.shape[1]\n",
    "        for i in range(0, e1_mask.shape[0], max_entity_pair):\n",
    "            yield {\n",
    "                \"input_ids\": torch.tensor([input_ids]).long().to(device), \n",
    "                \"attention_mask\": torch.ones((1, len(input_ids)), dtype=torch.long).to(device),\n",
    "                \"token_type_ids\": torch.zeros((1, len(input_ids)), dtype=torch.long).to(device),\n",
    "                \"e1_mask\": e1_mask[i: min(i+max_entity_pair, e1_mask.shape[0])].to(device),\n",
    "                \"e2_mask\": e2_mask[i: min(i+max_entity_pair, e1_mask.shape[0])].to(device)\n",
    "            }, {\n",
    "                \"offset\": offset,\n",
    "                \"candidate_relation_span\": candidate_relation_span[i: min(i+max_entity_pair, e1_mask.shape[0])]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "approximate-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_relation(re_model, doc, pred_entity_span, max_entity_pair=1000):\n",
    "    \"\"\"Predict the relation type in a document given the predicted entity spans\"\"\"\n",
    "    pred_relation_span = []\n",
    "    data_generator = prepare_doc(doc, pred_entity_span, max_entity_pair)\n",
    "    for inputs, infos in data_generator:\n",
    "        outputs = re_model(**inputs)\n",
    "        pred_label = F.softmax(outputs.logits, dim=-1).argmax(dim=1)\n",
    "        # print(pred_label)\n",
    "        for i in range(pred_label.shape[0]):\n",
    "            if pred_label[i] != 0:\n",
    "                candidate_relation = infos[\"candidate_relation_span\"][i]\n",
    "                pred_relation_span.append((candidate_relation[0], candidate_relation[1], pred_label[i].item()))\n",
    "    return pred_relation_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "compact-healthcare",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((23, 26, 2), (15, 16, 2), 1), ((23, 26, 2), (55, 56, 1), 4)]\n"
     ]
    }
   ],
   "source": [
    "# Test predict_relation()\n",
    "print(predict_relation(re_model, doc0, pred_entity_span))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "municipal-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(group, bert_model, ner_model, re_model, \n",
    "             entity_label_map, entity_classes,\n",
    "             relation_label_map, relation_classes,\n",
    "             max_entity_pair=1000):\n",
    "    true_entity_embeddings = []\n",
    "    pred_entity_embeddings = []\n",
    "    true_entity_spans = []\n",
    "    pred_entity_spans = []\n",
    "    true_relation_spans = []\n",
    "    pred_relation_spans = []\n",
    "    \n",
    "    data = parser.extract_data(group)\n",
    "    for doc in tqdm(data, total=len(data), desc=\"Evaluation \" + group):\n",
    "        token_df, label_df = transform_doc(doc, bert_model)\n",
    "        \n",
    "        # entity recognition\n",
    "        true_entity_embedding, pred_entity_embedding, true_entity_span, pred_entity_span \\\n",
    "            = predict_entity(ner_model, token_df, label_df)\n",
    "        true_entity_embeddings += true_entity_embedding.tolist()\n",
    "        pred_entity_embeddings += pred_entity_embedding.tolist()\n",
    "        true_entity_spans.append(true_entity_span)\n",
    "        pred_entity_spans.append(pred_entity_span)\n",
    "        \n",
    "        true_relation_span = get_true_relation_span(doc)\n",
    "        true_relation_spans.append(true_relation_span)\n",
    "        \n",
    "        # relation extraction\n",
    "        pred_relation_span = predict_relation(re_model, doc, pred_entity_span, \n",
    "                                              max_entity_pair=max_entity_pair)\n",
    "        pred_relation_spans.append(pred_relation_span)\n",
    "        \n",
    "    results = pd.concat([\n",
    "        evaluator.evaluate_span(true_entity_spans, pred_entity_spans, entity_label_map, entity_classes),\n",
    "        evaluator.evaluate_results(true_entity_embeddings, pred_entity_embeddings, entity_label_map, entity_classes),\n",
    "        evaluator.evaluate_loose_relation_span(true_relation_spans, pred_relation_spans, relation_label_map, relation_classes),\n",
    "        evaluator.evaluate_span(true_relation_spans, pred_relation_spans, relation_label_map, relation_classes),\n",
    "    ], keys=[\"Entity span\", \"Entity embedding\", \"Loose relation\", \"Strict relation\"])\n",
    "    results.to_csv(\"../../model/re/conll04_evaluate_\" + group + \".csv\")\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "labeled-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation test: 100%|███████████████████████████████████████████████████████████████| 288/288 [02:35<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.814898  0.845433     0.829885    427.0\n",
      "                 I-Peop        0.863905  0.909657     0.886191    321.0\n",
      "                 I-Org         0.528226  0.661616     0.587444    198.0\n",
      "                 I-Other       0.649123  0.556391     0.599190    133.0\n",
      "                 macro         0.714038  0.743274     0.725678      NaN\n",
      "                 micro         0.750656  0.795181     0.772277      NaN\n",
      "Entity embedding I-Loc         0.942953  0.889241     0.915309    632.0\n",
      "                 I-Peop        0.985380  0.976812     0.981077    690.0\n",
      "                 I-Org         0.830189  0.801822     0.815759    439.0\n",
      "                 I-Other       0.886139  0.680608     0.769892    263.0\n",
      "                 macro         0.911165  0.837121     0.870510      NaN\n",
      "                 micro         0.927072  0.873024     0.899237      NaN\n",
      "Loose relation   Kill          0.722222  0.829787     0.772277     47.0\n",
      "                 Located_In    0.588235  0.531915     0.558659     94.0\n",
      "                 OrgBased_In   0.482759  0.533333     0.506787    105.0\n",
      "                 Live_In       0.416667  0.700000     0.522388    100.0\n",
      "                 Work_For      0.462963  0.657895     0.543478     76.0\n",
      "                 macro         0.534569  0.650586     0.580718      NaN\n",
      "                 micro         0.499058  0.627962     0.556139      NaN\n",
      "Strict relation  Kill          0.722222  0.829787     0.772277     47.0\n",
      "                 Located_In    0.443182  0.414894     0.428571     94.0\n",
      "                 OrgBased_In   0.322314  0.371429     0.345133    105.0\n",
      "                 Live_In       0.306818  0.540000     0.391304    100.0\n",
      "                 Work_For      0.252174  0.381579     0.303665     76.0\n",
      "                 macro         0.409342  0.507538     0.448190      NaN\n",
      "                 micro         0.361011  0.473934     0.409836      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"test\", bert_model, ner_model, re_model, \n",
    "         entity_label_map, entity_classes, relation_label_map, relation_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "advised-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentences, bert_model, ner_model, re_model, \n",
    "            entity_label_map, entity_classes,\n",
    "            relation_label_map, relation_classes,\n",
    "            max_entity_pair=1000):\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        word_list = sentence.split()\n",
    "        words = []\n",
    "        token_ids = []\n",
    "        ids = []\n",
    "        # transform a sentence to a document for prediction\n",
    "        for i, word in enumerate(word_list):\n",
    "            token_id = parser.tokenizer(word)[\"input_ids\"][1:-1]\n",
    "            for tid in token_id:\n",
    "                words.append(word)\n",
    "                token_ids.append(tid)\n",
    "                ids.append(i)\n",
    "        data_frame = pd.DataFrame()\n",
    "        data_frame[\"words\"] = words\n",
    "        data_frame[\"token_ids\"] = token_ids\n",
    "        data_frame[\"ids\"] = ids\n",
    "        data_frame[\"entity_embedding\"] = 0\n",
    "        data_frame[\"sentence_embedding\"] = 0\n",
    "        doc = {\"data_frame\": data_frame,\n",
    "            \"entity_position\": {}, # Suppose to appear in non-overlapping dataset\n",
    "            \"relations\": {}}\n",
    "        # predict\n",
    "        token_df, label_df = transform_doc(doc, bert_model)\n",
    "        \n",
    "        # entity recognition\n",
    "        true_entity_embedding, pred_entity_embedding, true_entity_span, pred_entity_span \\\n",
    "            = predict_entity(ner_model, token_df, label_df)\n",
    "        \n",
    "        # relation extraction\n",
    "        pred_relation_span = predict_relation(re_model, doc, pred_entity_span,  \n",
    "                                              max_entity_pair=max_entity_pair)\n",
    "        # print result\n",
    "        tokens = parser.tokenizer.convert_ids_to_tokens(token_ids)\n",
    "        print(\"Sentence:\", sentence)\n",
    "        print(\"Entities: (\", len(pred_entity_span), \")\")\n",
    "        for begin, end, entity_type in pred_entity_span:\n",
    "            print(entity_label_map[entity_type], \"|\", \" \".join(tokens[begin:end]))\n",
    "        print(\"Relations: (\", len(pred_relation_span), \")\")\n",
    "        for e1, e2, relation_type in pred_relation_span:\n",
    "            print(relation_label_map[relation_type], \"|\", \n",
    "                  \" \".join(tokens[e1[0]:e1[1]]), \"|\", \n",
    "                  \" \".join(tokens[e2[0]:e2[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hired-exploration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: However, the Rev. Jesse Jackson, a native of South Carolina, joined critics of FEMA's effort.\n",
      "Entities: ( 4 )\n",
      "I-Peop | rev .\n",
      "I-Peop | jesse jackson ,\n",
      "I-Loc | south carolina ,\n",
      "I-Org | fe ##ma ' s\n",
      "Relations: ( 3 )\n",
      "Live_In | rev . | south carolina ,\n",
      "Live_In | jesse jackson , | south carolina ,\n",
      "Work_For | jesse jackson , | fe ##ma ' s\n",
      "Sentence: International Paper spokeswoman Ann Silvernail said that under French law the company was barred from releasing details pending government approval.\n",
      "Entities: ( 2 )\n",
      "I-Org | international\n",
      "I-Peop | ann silver ##nail\n",
      "Relations: ( 1 )\n",
      "Work_For | ann silver ##nail | international\n"
     ]
    }
   ],
   "source": [
    "predict([\"However, the Rev. Jesse Jackson, a native of South Carolina, joined critics of FEMA's effort.\", \n",
    "         \"International Paper spokeswoman Ann Silvernail said that under French law the company was barred from releasing details pending government approval.\"], \n",
    "        bert_model, ner_model, re_model, \n",
    "        entity_label_map, entity_classes, relation_label_map, relation_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-india",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

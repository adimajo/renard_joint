{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "structured-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "allied-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AdamW, BertConfig, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "juvenile-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elder-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this part for different dataset\n",
    "import conll04_constants as constants\n",
    "import conll04_input_generator as input_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "objective-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "weighted-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "precise-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To run reference model\n",
    "# input_generator.parser.entity_encode = {'O': 0, 'B-Loc': 1, 'I-Loc': 1, 'B-Peop': 3, 'I-Peop': 3, \n",
    "#                                          'B-Org': 2, 'I-Org': 2, 'B-Other': 4, 'I-Other': 4}\n",
    "# input_generator.parser.relation_encode = {'N': 0, 'Kill': 2, 'Located_In': 5, 'OrgBased_In': 3,\n",
    "#                                            'Live_In': 4, 'Work_For': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "advanced-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_label_map = {v: k for k, v in input_generator.parser.entity_encode.items()}\n",
    "entity_classes = list(entity_label_map.keys())\n",
    "entity_classes.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "absolute-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_label_map = {v: k for k, v in input_generator.parser.relation_encode.items()}\n",
    "relation_classes = list(relation_label_map.keys())\n",
    "relation_classes.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "phantom-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(constants.model_path)\n",
    "input_generator.parser.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "french-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_params(model):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_params = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': constants.weight_decay},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': 0.0}]\n",
    "    return optimizer_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "anonymous-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_first_tokens(embedding, words):\n",
    "    \"\"\"Take the embedding of the first token of each word\"\"\"\n",
    "    reduced_embedding = []\n",
    "    for i, word in enumerate(words):\n",
    "        if i == 0 or word != words[i-1]:\n",
    "            reduced_embedding.append(embedding[i])\n",
    "    return reduced_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "elegant-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(spert_model, group):\n",
    "    spert_model.eval()\n",
    "    eval_entity_span_pred = []\n",
    "    eval_entity_span_true = []\n",
    "    eval_entity_embedding_pred = []\n",
    "    eval_entity_embedding_true = []\n",
    "    eval_relation_span_pred = []\n",
    "    eval_relation_span_true = []\n",
    "    eval_generator = input_generator.data_generator(group, device, \n",
    "                                                    is_training=False,\n",
    "                                                    neg_entity_count=constants.neg_entity_count, \n",
    "                                                    neg_relation_count=constants.neg_relation_count, \n",
    "                                                    max_span_size=constants.max_span_size)\n",
    "    eval_dataset = list(eval_generator)\n",
    "    eval_size = len(eval_dataset)\n",
    "    for inputs, infos in tqdm(eval_dataset, total=eval_size, desc=\"Evaluation \"+group):\n",
    "        # forward\n",
    "        outputs = spert_model(**inputs, is_training=False)\n",
    "        # retrieve results for evaluation\n",
    "        eval_entity_span_pred.append(outputs[\"entity\"][\"span\"])\n",
    "        eval_entity_span_true.append(infos[\"entity_span\"])\n",
    "        if not constants.is_overlapping:\n",
    "            eval_entity_embedding_pred += take_first_tokens(outputs[\"entity\"][\"embedding\"].tolist(), infos[\"words\"])\n",
    "            eval_entity_embedding_true += take_first_tokens(infos[\"entity_embedding\"].tolist(), infos[\"words\"])\n",
    "            assert len(eval_entity_embedding_pred) == len(eval_entity_embedding_true)\n",
    "        eval_relation_span_pred.append([] if outputs[\"relation\"] == None else outputs[\"relation\"][\"span\"])\n",
    "        eval_relation_span_true.append(infos[\"relation_span\"])\n",
    "    # evaluate & save\n",
    "    results = pd.concat([\n",
    "        evaluator.evaluate_span(eval_entity_span_true, eval_entity_span_pred, entity_label_map, entity_classes),\n",
    "        evaluator.evaluate_results(eval_entity_embedding_true, eval_entity_embedding_pred, entity_label_map, entity_classes),\n",
    "        evaluator.evaluate_loose_relation_span(eval_relation_span_true, eval_relation_span_pred, relation_label_map, relation_classes),\n",
    "        evaluator.evaluate_span(eval_relation_span_true, eval_relation_span_pred, relation_label_map, relation_classes),\n",
    "    ], keys=[\"Entity span\", \"Entity embedding\", \"Loose relation\", \"Strict relation\"])\n",
    "    results.to_csv(constants.model_save_path + \"evaluate_\" + group + \".csv\")\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extended-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"Train the model and evaluate on the dev dataset\n",
    "    \"\"\"\n",
    "    # Training\n",
    "    train_generator = input_generator.data_generator(constants.train_dataset, device, \n",
    "                                                     is_training=True,\n",
    "                                                     neg_entity_count=constants.neg_entity_count, \n",
    "                                                     neg_relation_count=constants.neg_relation_count, \n",
    "                                                     max_span_size=constants.max_span_size)\n",
    "    train_dataset = list(train_generator)\n",
    "    train_size = len(train_dataset)\n",
    "    config = BertConfig.from_pretrained(constants.model_path)\n",
    "    spert_model = model.SpERT.from_pretrained(constants.model_path,\n",
    "                                              config=config,\n",
    "                                              # SpERT model parameters\n",
    "                                              relation_types=constants.relation_types, \n",
    "                                              entity_types=constants.entity_types, \n",
    "                                              width_embedding_size=constants.width_embedding_size, \n",
    "                                              prop_drop=constants.prop_drop, \n",
    "                                              freeze_transformer=True, \n",
    "                                              max_pairs=constants.max_pairs, \n",
    "                                              is_overlapping=constants.is_overlapping, \n",
    "                                              relation_filter_threshold=constants.relation_filter_threshold)\n",
    "    spert_model.to(device)\n",
    "    optimizer_params = get_optimizer_params(spert_model)\n",
    "    optimizer = AdamW(optimizer_params, lr=constants.lr, weight_decay=constants.weight_decay, correct_bias=False)\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup(optimizer, \n",
    "                             num_warmup_steps=constants.lr_warmup*train_size*constants.epochs, \n",
    "                             num_training_steps=train_size*constants.epochs)\n",
    "    for epoch in range(constants.epochs):\n",
    "        losses = []\n",
    "        train_entity_pred = []\n",
    "        train_entity_true = []\n",
    "        train_relation_pred = []\n",
    "        train_relation_true = []\n",
    "        spert_model.zero_grad()\n",
    "        for inputs, infos in tqdm(train_dataset, total=train_size, desc='Train epoch %s' % epoch):\n",
    "            spert_model.train()\n",
    "            # forward\n",
    "            outputs = spert_model(**inputs, is_training=True)\n",
    "            # backward\n",
    "            loss = outputs[\"loss\"]\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(spert_model.parameters(), constants.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            spert_model.zero_grad()\n",
    "            # print(optimizer.param_groups[0]['lr'])\n",
    "            # retrieve results for evaluation\n",
    "            losses.append(loss.item())\n",
    "            train_entity_pred += outputs[\"entity\"][\"pred\"].tolist()\n",
    "            train_entity_true += inputs[\"entity_label\"].tolist()\n",
    "            train_relation_pred += [] if outputs[\"relation\"] == None else outputs[\"relation\"][\"pred\"].tolist()\n",
    "            train_relation_true += inputs[\"relation_label\"].tolist()\n",
    "            assert len(train_entity_pred) == len(train_entity_true)\n",
    "            assert len(train_relation_pred) == len(train_relation_true)\n",
    "            \n",
    "        # evaluate & save checkpoint\n",
    "        print(\"epoch:\", epoch,\"average loss:\", sum(losses) / len(losses))\n",
    "        results = pd.concat([\n",
    "            evaluator.evaluate_results(train_entity_true, train_entity_pred, entity_label_map, entity_classes),\n",
    "            evaluator.evaluate_results(train_relation_true, train_relation_pred, relation_label_map, relation_classes)\n",
    "        ], keys=[\"Entity\", \"Relation\"])\n",
    "        results.to_csv(constants.model_save_path + \"epoch_\" + str(epoch) + \".csv\")\n",
    "        evaluate(spert_model, constants.dev_dataset)\n",
    "        \n",
    "    torch.save(spert_model.state_dict(), constants.model_save_path + \"epoch_\" + str(constants.epochs-1) + \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "animated-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(spert_model, sentences):\n",
    "    for sentence in sentences:\n",
    "        word_list = sentence.split()\n",
    "        words = []\n",
    "        token_ids = []\n",
    "        # transform a sentence to a document for prediction\n",
    "        for word in word_list:\n",
    "            token_id = tokenizer(word)[\"input_ids\"][1:-1]\n",
    "            for tid in token_id:\n",
    "                words.append(word)\n",
    "                token_ids.append(tid)\n",
    "        data_frame = pd.DataFrame()\n",
    "        data_frame[\"words\"] = words\n",
    "        data_frame[\"token_ids\"] = token_ids\n",
    "        data_frame[\"entity_embedding\"] = 0\n",
    "        data_frame[\"sentence_embedding\"] = 0 # for internal datasets\n",
    "        doc = {\"data_frame\": data_frame,\n",
    "            \"entity_position\": {}, # Suppose to appear in non-overlapping dataset\n",
    "            \"entities\": {}, # Suppose to appear in overlapping dataset\n",
    "            \"relations\": {}}\n",
    "        # predict\n",
    "        inputs, infos = input_generator.doc_to_input(doc, device, \n",
    "                                                     is_training=False, \n",
    "                                                     max_span_size=constants.max_span_size)\n",
    "        outputs = spert_model(**inputs, is_training=False)\n",
    "        pred_entity_span = outputs[\"entity\"][\"span\"]\n",
    "        pred_relation_span = [] if outputs[\"relation\"] is None else outputs[\"relation\"][\"span\"]\n",
    "        # print result\n",
    "        tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "        print(\"Sentence:\", sentence)\n",
    "        print(\"Entities: (\", len(pred_entity_span), \")\")\n",
    "        for begin, end, entity_type in pred_entity_span:\n",
    "            print(entity_label_map[entity_type], \"|\", \" \".join(tokens[begin:end]))\n",
    "        print(\"Relations: (\", len(pred_relation_span), \")\")\n",
    "        for e1, e2, relation_type in pred_relation_span:\n",
    "            print(relation_label_map[relation_type], \"|\", \n",
    "                  \" \".join(tokens[e1[0]:e1[1]]), \"|\", \n",
    "                  \" \".join(tokens[e2[0]:e2[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "least-accent",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing SpERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing SpERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SpERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SpERT were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['relation_classifier.weight', 'relation_classifier.bias', 'entity_classifier.weight', 'entity_classifier.bias', 'width_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Train epoch 0:   9%|██████                                                            | 84/910 [00:22<03:38,  3.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-3ede53b9aa5b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mspert_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;31m# forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspert_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m             \u001b[1;31m# backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Work\\renard_joint\\spert\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, entity_mask, entity_label, relation_mask, relation_label, is_training)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 is_training: bool = True):\n\u001b[0;32m    221\u001b[0m         \u001b[1;31m# get the last hidden layer from BERT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         bert_embedding = self.bert(input_ids=input_ids, \n\u001b[0m\u001b[0;32m    223\u001b[0m                                    \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                                    token_type_ids=token_type_ids)['last_hidden_state']\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\transformers-4.2.1-py3.8.egg\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    956\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         )\n\u001b[1;32m--> 958\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    959\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\transformers-4.2.1-py3.8.egg\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    557\u001b[0m                 )\n\u001b[0;32m    558\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    560\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\transformers-4.2.1-py3.8.egg\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[0;32m    496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         )\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\transformers-4.2.1-py3.8.egg\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m   1785\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1787\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\transformers-4.2.1-py3.8.egg\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\transformers-4.2.1-py3.8.egg\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\work\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1692\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-message",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(constants.model_path)\n",
    "spert_model = model.SpERT.from_pretrained(constants.model_path,\n",
    "                                          config=config,\n",
    "                                          # SpERT model parameters\n",
    "                                          relation_types=constants.relation_types, \n",
    "                                          entity_types=constants.entity_types, \n",
    "                                          width_embedding_size=constants.width_embedding_size, \n",
    "                                          prop_drop=constants.prop_drop, \n",
    "                                          freeze_transformer=True, \n",
    "                                          max_pairs=constants.max_pairs, \n",
    "                                          is_overlapping=constants.is_overlapping, \n",
    "                                          relation_filter_threshold=constants.relation_filter_threshold)\n",
    "spert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(constants.model_save_path + \"epoch_\" + str(constants.epochs-1) + \".model\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To run reference model\n",
    "# state_dict = torch.load(\"../../model/spert/reference/reference_model.bin\")\n",
    "# state_dict[\"relation_classifier.weight\"] = state_dict[\"rel_classifier.weight\"]\n",
    "# state_dict[\"relation_classifier.bias\"] = state_dict[\"rel_classifier.bias\"]\n",
    "# state_dict[\"width_embedding.weight\"] = state_dict[\"size_embeddings.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "spert_model.load_state_dict(state_dict, strict=False)\n",
    "evaluate(spert_model, constants.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load(constants.model_save_path + \"epoch_\" + str(constants.epochs-1) + \".model\")\n",
    "# state_dict[\"rel_classifier.weight\"] = state_dict[\"relation_classifier.weight\"]\n",
    "# state_dict[\"rel_classifier.bias\"] = state_dict[\"relation_classifier.bias\"]\n",
    "# state_dict[\"size_embeddings.weight\"] = state_dict[\"width_embedding.weight\"]\n",
    "# del state_dict[\"relation_classifier.weight\"]\n",
    "# del state_dict[\"relation_classifier.bias\"]\n",
    "# del state_dict[\"width_embedding.weight\"]\n",
    "# del state_dict[\"bert.embeddings.position_ids\"]\n",
    "# torch.save(state_dict, \"../../model/spert/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(spert_model, sentences=[\"However, the Rev. Jesse Jackson, a native of South Carolina, joined critics of FEMA's effort.\", \n",
    "#                                 \"International Paper spokeswoman Ann Silvernail said that under French law the company was barred from releasing details pending government approval.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \" \".join([\"An\", \"art\", \"exhibit\", \"at\", \"the\", \"Hakawati\", \"Theatre\", \"in\", \"Arab\", \"east\", \"Jerusalem\", \"was\", \"a\", \"series\", \"of\", \"portraits\", \"of\", \"Palestinians\", \"killed\", \"in\", \"the\", \"rebellion\", \".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"entities\": [{\"type\": \"Loc\", \"start\": 5, \"end\": 7}, {\"type\": \"Loc\", \"start\": 10, \"end\": 11}, {\"type\": \"Other\", \"start\": 17, \"end\": 18}], \"relations\": [{\"type\": \"Located_In\", \"head\": 0, \"tail\": 1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(spert_model, sentences=[test_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sentence = \" \".join([\"PERUGIA\", \",\", \"Italy\", \"(\", \"AP\", \")\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(spert_model, sentences=[test_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-insurance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

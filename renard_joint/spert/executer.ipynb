{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AdamW, BertConfig, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this part for different dataset\n",
    "import scierc_constants as constants\n",
    "import scierc_input_generator as input_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To run reference model\n",
    "# input_generator.parser.entity_encode = {'O': 0, 'B-Loc': 1, 'I-Loc': 1, 'B-Peop': 3, 'I-Peop': 3, \n",
    "#                                          'B-Org': 2, 'I-Org': 2, 'B-Other': 4, 'I-Other': 4}\n",
    "# input_generator.parser.relation_encode = {'N': 0, 'Kill': 2, 'Located_In': 5, 'OrgBased_In': 3,\n",
    "#                                            'Live_In': 4, 'Work_For': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_label_map = {v: k for k, v in input_generator.parser.entity_encode.items()}\n",
    "entity_classes = list(entity_label_map.keys())\n",
    "entity_classes.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_label_map = {v: k for k, v in input_generator.parser.relation_encode.items()}\n",
    "relation_classes = list(relation_label_map.keys())\n",
    "relation_classes.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(constants.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_params(model):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_params = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': constants.weight_decay},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': 0.0}]\n",
    "    return optimizer_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(spert_model, group):\n",
    "    spert_model.eval()\n",
    "    eval_entity_span_pred = []\n",
    "    eval_entity_span_true = []\n",
    "    eval_entity_embedding_pred = []\n",
    "    eval_entity_embedding_true = []\n",
    "    eval_relation_span_pred = []\n",
    "    eval_relation_span_true = []\n",
    "    eval_generator = input_generator.data_generator(group, device, \n",
    "                                                    is_training=False,\n",
    "                                                    neg_entity_count=constants.neg_entity_count, \n",
    "                                                    neg_relation_count=constants.neg_relation_count, \n",
    "                                                    max_span_size=constants.max_span_size)\n",
    "    eval_dataset = list(eval_generator)\n",
    "    eval_size = len(eval_dataset)\n",
    "    for inputs, infos in tqdm(eval_dataset, total=eval_size, desc=\"Evaluation \"+group):\n",
    "        # forward\n",
    "        outputs = spert_model(**inputs, is_training=False)\n",
    "        # retrieve results for evaluation\n",
    "        eval_entity_span_pred.append(outputs[\"entity\"][\"span\"])\n",
    "        eval_entity_span_true.append(infos[\"entity_span\"])\n",
    "        if not constants.is_overlapping:\n",
    "            eval_entity_embedding_pred += outputs[\"entity\"][\"embedding\"].tolist()\n",
    "            eval_entity_embedding_true += infos[\"entity_embedding\"].tolist()\n",
    "            assert len(eval_entity_embedding_pred) == len(eval_entity_embedding_true)\n",
    "        eval_relation_span_pred.append([] if outputs[\"relation\"] == None else outputs[\"relation\"][\"span\"])\n",
    "        eval_relation_span_true.append(infos[\"relation_span\"])\n",
    "    # evaluate & save\n",
    "    results = pd.concat([\n",
    "        evaluator.evaluate_span(eval_entity_span_true, eval_entity_span_pred, entity_label_map, entity_classes),\n",
    "        evaluator.evaluate_results(eval_entity_embedding_true, eval_entity_embedding_pred, entity_label_map, entity_classes),\n",
    "        evaluator.evaluate_loose_relation_span(eval_relation_span_true, eval_relation_span_pred, relation_label_map, relation_classes),\n",
    "        evaluator.evaluate_span(eval_relation_span_true, eval_relation_span_pred, relation_label_map, relation_classes),\n",
    "    ], keys=[\"Entity span\", \"Entity embedding\", \"Loose relation\", \"Strict relation\"])\n",
    "    results.to_csv(constants.model_save_path + \"evaluate_\" + group + \".csv\")\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"Train the model and evaluate on the dev dataset\n",
    "    \"\"\"\n",
    "    # Training\n",
    "    train_generator = input_generator.data_generator(constants.train_dataset, device, \n",
    "                                                     is_training=True,\n",
    "                                                     neg_entity_count=constants.neg_entity_count, \n",
    "                                                     neg_relation_count=constants.neg_relation_count, \n",
    "                                                     max_span_size=constants.max_span_size)\n",
    "    train_dataset = list(train_generator)\n",
    "    train_size = len(train_dataset)\n",
    "    config = BertConfig.from_pretrained(constants.model_path)\n",
    "    spert_model = model.SpERT.from_pretrained(constants.model_path,\n",
    "                                              config=config,\n",
    "                                              # SpERT model parameters\n",
    "                                              relation_types=constants.relation_types, \n",
    "                                              entity_types=constants.entity_types, \n",
    "                                              width_embedding_size=constants.width_embedding_size, \n",
    "                                              prop_drop=constants.prop_drop, \n",
    "                                              freeze_transformer=True, \n",
    "                                              max_pairs=constants.max_pairs, \n",
    "                                              is_overlapping=constants.is_overlapping, \n",
    "                                              relation_filter_threshold=constants.relation_filter_threshold)\n",
    "    spert_model.to(device)\n",
    "    optimizer_params = get_optimizer_params(spert_model)\n",
    "    optimizer = AdamW(optimizer_params, lr=constants.lr, weight_decay=constants.weight_decay, correct_bias=False)\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup(optimizer, \n",
    "                             num_warmup_steps=constants.lr_warmup*train_size*constants.epochs, \n",
    "                             num_training_steps=train_size*constants.epochs)\n",
    "    for epoch in range(constants.epochs):\n",
    "        losses = []\n",
    "        train_entity_pred = []\n",
    "        train_entity_true = []\n",
    "        train_relation_pred = []\n",
    "        train_relation_true = []\n",
    "        spert_model.zero_grad()\n",
    "        for inputs, infos in tqdm(train_dataset, total=train_size, desc='Train epoch %s' % epoch):\n",
    "            spert_model.train()\n",
    "            # forward\n",
    "            outputs = spert_model(**inputs, is_training=True)\n",
    "            # backward\n",
    "            loss = outputs[\"loss\"]\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(spert_model.parameters(), constants.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            spert_model.zero_grad()\n",
    "            # print(optimizer.param_groups[0]['lr'])\n",
    "            # retrieve results for evaluation\n",
    "            losses.append(loss.item())\n",
    "            train_entity_pred += outputs[\"entity\"][\"pred\"].tolist()\n",
    "            train_entity_true += inputs[\"entity_label\"].tolist()\n",
    "            train_relation_pred += [] if outputs[\"relation\"] == None else outputs[\"relation\"][\"pred\"].tolist()\n",
    "            train_relation_true += inputs[\"relation_label\"].tolist()\n",
    "            assert len(train_entity_pred) == len(train_entity_true)\n",
    "            assert len(train_relation_pred) == len(train_relation_true)\n",
    "            \n",
    "        # evaluate & save checkpoint\n",
    "        print(\"epoch:\", epoch,\"average loss:\", sum(losses) / len(losses))\n",
    "        results = pd.concat([\n",
    "            evaluator.evaluate_results(train_entity_true, train_entity_pred, entity_label_map, entity_classes),\n",
    "            evaluator.evaluate_results(train_relation_true, train_relation_pred, relation_label_map, relation_classes)\n",
    "        ], keys=[\"Entity\", \"Relation\"])\n",
    "        results.to_csv(constants.model_save_path + \"epoch_\" + str(epoch) + \".csv\")\n",
    "        evaluate(spert_model, constants.dev_dataset)\n",
    "        \n",
    "    torch.save(spert_model.state_dict(), constants.model_save_path + \"epoch_\" + str(constants.epochs-1) + \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(spert_model, sentences):\n",
    "    for sentence in sentences:\n",
    "        word_list = sentence.split()\n",
    "        words = []\n",
    "        token_ids = []\n",
    "        # transform a sentence to a document for prediction\n",
    "        for word in word_list:\n",
    "            token_id = tokenizer(word)[\"input_ids\"][1:-1]\n",
    "            for tid in token_id:\n",
    "                words.append(word)\n",
    "                token_ids.append(tid)\n",
    "        data_frame = pd.DataFrame()\n",
    "        data_frame[\"words\"] = words\n",
    "        data_frame[\"token_ids\"] = token_ids\n",
    "        data_frame[\"entity_embedding\"] = 0\n",
    "        doc = {\"data_frame\": data_frame,\n",
    "            \"entity_position\": {}, # Suppose to appear in non-overlapping dataset\n",
    "            \"entities\": {}, # Suppose to appear in overlapping dataset\n",
    "            \"relations\": {}}\n",
    "        # predict\n",
    "        inputs, infos = input_generator.doc_to_input(doc, device, \n",
    "                                                     is_training=False, \n",
    "                                                     max_span_size=constants.max_span_size)\n",
    "        outputs = spert_model(**inputs, is_training=False)\n",
    "        pred_entity_span = outputs[\"entity\"][\"span\"]\n",
    "        pred_relation_span = [] if outputs[\"relation\"] is None else outputs[\"relation\"][\"span\"]\n",
    "        # print result\n",
    "        tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "        print(\"Sentence:\", sentence)\n",
    "        print(\"Entities: (\", len(pred_entity_span), \")\")\n",
    "        for begin, end, entity_type in pred_entity_span:\n",
    "            print(entity_label_map[entity_type], \"|\", \" \".join(tokens[begin:end]))\n",
    "        print(\"Relations: (\", len(pred_relation_span), \")\")\n",
    "        for e1, e2, relation_type in pred_relation_span:\n",
    "            print(relation_label_map[relation_type], \"|\", \n",
    "                  \" \".join(tokens[e1[0]:e1[1]]), \"|\", \n",
    "                  \" \".join(tokens[e2[0]:e2[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-modem",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-embassy",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(constants.model_path)\n",
    "spert_model = model.SpERT.from_pretrained(constants.model_path,\n",
    "                                          config=config,\n",
    "                                          # SpERT model parameters\n",
    "                                          relation_types=constants.relation_types, \n",
    "                                          entity_types=constants.entity_types, \n",
    "                                          width_embedding_size=constants.width_embedding_size, \n",
    "                                          prop_drop=constants.prop_drop, \n",
    "                                          freeze_transformer=True, \n",
    "                                          max_pairs=constants.max_pairs, \n",
    "                                          is_overlapping=constants.is_overlapping, \n",
    "                                          relation_filter_threshold=constants.relation_filter_threshold)\n",
    "spert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(constants.model_save_path + \"epoch_\" + str(constants.epochs-1) + \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To run reference model\n",
    "# state_dict = torch.load(\"../../model/spert/reference/reference_model.bin\")\n",
    "# state_dict[\"relation_classifier.weight\"] = state_dict[\"rel_classifier.weight\"]\n",
    "# state_dict[\"relation_classifier.bias\"] = state_dict[\"rel_classifier.bias\"]\n",
    "# state_dict[\"width_embedding.weight\"] = state_dict[\"size_embeddings.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "spert_model.load_state_dict(state_dict, strict=False)\n",
    "evaluate(spert_model, constants.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load(constants.model_save_path + \"epoch_\" + str(constants.epochs-1) + \".model\")\n",
    "# state_dict[\"rel_classifier.weight\"] = state_dict[\"relation_classifier.weight\"]\n",
    "# state_dict[\"rel_classifier.bias\"] = state_dict[\"relation_classifier.bias\"]\n",
    "# state_dict[\"size_embeddings.weight\"] = state_dict[\"width_embedding.weight\"]\n",
    "# del state_dict[\"relation_classifier.weight\"]\n",
    "# del state_dict[\"relation_classifier.bias\"]\n",
    "# del state_dict[\"width_embedding.weight\"]\n",
    "# del state_dict[\"bert.embeddings.position_ids\"]\n",
    "# torch.save(state_dict, \"../../model/spert/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(spert_model, sentences=[\"However, the Rev. Jesse Jackson, a native of South Carolina, joined critics of FEMA's effort.\", \n",
    "                                \"International Paper spokeswoman Ann Silvernail said that under French law the company was barred from releasing details pending government approval.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-column",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

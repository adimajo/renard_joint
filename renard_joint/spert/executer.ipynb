{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acute-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "operational-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AdamW, BertConfig, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conventional-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "junior-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this part for different dataset\n",
    "import conll04_constants as constants\n",
    "import conll04_input_generator as input_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "happy-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interested-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alert-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To run reference model\n",
    "# input_generator.parser.entity_encode = {'O': 0, 'B-Loc': 1, 'I-Loc': 1, 'B-Peop': 3, 'I-Peop': 3, \n",
    "#                                          'B-Org': 2, 'I-Org': 2, 'B-Other': 4, 'I-Other': 4}\n",
    "# input_generator.parser.relation_encode = {'N': 0, 'Kill': 2, 'Located_In': 5, 'OrgBased_In': 3,\n",
    "#                                            'Live_In': 4, 'Work_For': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "excellent-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_label_map = {v: k for k, v in input_generator.parser.entity_encode.items()}\n",
    "entity_classes = list(entity_label_map.keys())\n",
    "entity_classes.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "breeding-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_label_map = {v: k for k, v in input_generator.parser.relation_encode.items()}\n",
    "relation_classes = list(relation_label_map.keys())\n",
    "relation_classes.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rolled-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(constants.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affiliated-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_params(model):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_params = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': constants.weight_decay},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': 0.0}]\n",
    "    return optimizer_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ignored-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_first_tokens(embedding, words):\n",
    "    \"\"\"Take the embedding of the first token of each word\"\"\"\n",
    "    reduced_embedding = []\n",
    "    for i, word in enumerate(words):\n",
    "        if i == 0 or word != words[i-1]:\n",
    "            reduced_embedding.append(embedding[i])\n",
    "    return reduced_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "forced-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(spert_model, group):\n",
    "    spert_model.eval()\n",
    "    eval_entity_span_pred = []\n",
    "    eval_entity_span_true = []\n",
    "    eval_entity_embedding_pred = []\n",
    "    eval_entity_embedding_true = []\n",
    "    eval_relation_span_pred = []\n",
    "    eval_relation_span_true = []\n",
    "    eval_generator = input_generator.data_generator(group, device, \n",
    "                                                    is_training=False,\n",
    "                                                    neg_entity_count=constants.neg_entity_count, \n",
    "                                                    neg_relation_count=constants.neg_relation_count, \n",
    "                                                    max_span_size=constants.max_span_size)\n",
    "    eval_dataset = list(eval_generator)\n",
    "    eval_size = len(eval_dataset)\n",
    "    for inputs, infos in tqdm(eval_dataset, total=eval_size, desc=\"Evaluation \"+group):\n",
    "        # forward\n",
    "        outputs = spert_model(**inputs, is_training=False)\n",
    "        # retrieve results for evaluation\n",
    "        eval_entity_span_pred.append(outputs[\"entity\"][\"span\"])\n",
    "        eval_entity_span_true.append(infos[\"entity_span\"])\n",
    "        if not constants.is_overlapping:\n",
    "            eval_entity_embedding_pred += take_first_tokens(outputs[\"entity\"][\"embedding\"].tolist(), infos[\"words\"])\n",
    "            eval_entity_embedding_true += take_first_tokens(infos[\"entity_embedding\"].tolist(), infos[\"words\"])\n",
    "            assert len(eval_entity_embedding_pred) == len(eval_entity_embedding_true)\n",
    "        eval_relation_span_pred.append([] if outputs[\"relation\"] == None else outputs[\"relation\"][\"span\"])\n",
    "        eval_relation_span_true.append(infos[\"relation_span\"])\n",
    "    # evaluate & save\n",
    "    results = pd.concat([\n",
    "        evaluator.evaluate_span(eval_entity_span_true, eval_entity_span_pred, entity_label_map, entity_classes),\n",
    "        evaluator.evaluate_results(eval_entity_embedding_true, eval_entity_embedding_pred, entity_label_map, entity_classes),\n",
    "        evaluator.evaluate_loose_relation_span(eval_relation_span_true, eval_relation_span_pred, relation_label_map, relation_classes),\n",
    "        evaluator.evaluate_span(eval_relation_span_true, eval_relation_span_pred, relation_label_map, relation_classes),\n",
    "    ], keys=[\"Entity span\", \"Entity embedding\", \"Loose relation\", \"Strict relation\"])\n",
    "    results.to_csv(constants.model_save_path + \"evaluate_\" + group + \".csv\")\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hungry-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"Train the model and evaluate on the dev dataset\n",
    "    \"\"\"\n",
    "    # Training\n",
    "    train_generator = input_generator.data_generator(constants.train_dataset, device, \n",
    "                                                     is_training=True,\n",
    "                                                     neg_entity_count=constants.neg_entity_count, \n",
    "                                                     neg_relation_count=constants.neg_relation_count, \n",
    "                                                     max_span_size=constants.max_span_size)\n",
    "    train_dataset = list(train_generator)\n",
    "    train_size = len(train_dataset)\n",
    "    config = BertConfig.from_pretrained(constants.model_path)\n",
    "    spert_model = model.SpERT.from_pretrained(constants.model_path,\n",
    "                                              config=config,\n",
    "                                              # SpERT model parameters\n",
    "                                              relation_types=constants.relation_types, \n",
    "                                              entity_types=constants.entity_types, \n",
    "                                              width_embedding_size=constants.width_embedding_size, \n",
    "                                              prop_drop=constants.prop_drop, \n",
    "                                              freeze_transformer=True, \n",
    "                                              max_pairs=constants.max_pairs, \n",
    "                                              is_overlapping=constants.is_overlapping, \n",
    "                                              relation_filter_threshold=constants.relation_filter_threshold)\n",
    "    spert_model.to(device)\n",
    "    optimizer_params = get_optimizer_params(spert_model)\n",
    "    optimizer = AdamW(optimizer_params, lr=constants.lr, weight_decay=constants.weight_decay, correct_bias=False)\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup(optimizer, \n",
    "                             num_warmup_steps=constants.lr_warmup*train_size*constants.epochs, \n",
    "                             num_training_steps=train_size*constants.epochs)\n",
    "    for epoch in range(constants.epochs):\n",
    "        losses = []\n",
    "        train_entity_pred = []\n",
    "        train_entity_true = []\n",
    "        train_relation_pred = []\n",
    "        train_relation_true = []\n",
    "        spert_model.zero_grad()\n",
    "        for inputs, infos in tqdm(train_dataset, total=train_size, desc='Train epoch %s' % epoch):\n",
    "            spert_model.train()\n",
    "            # forward\n",
    "            outputs = spert_model(**inputs, is_training=True)\n",
    "            # backward\n",
    "            loss = outputs[\"loss\"]\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(spert_model.parameters(), constants.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            spert_model.zero_grad()\n",
    "            # print(optimizer.param_groups[0]['lr'])\n",
    "            # retrieve results for evaluation\n",
    "            losses.append(loss.item())\n",
    "            train_entity_pred += outputs[\"entity\"][\"pred\"].tolist()\n",
    "            train_entity_true += inputs[\"entity_label\"].tolist()\n",
    "            train_relation_pred += [] if outputs[\"relation\"] == None else outputs[\"relation\"][\"pred\"].tolist()\n",
    "            train_relation_true += inputs[\"relation_label\"].tolist()\n",
    "            assert len(train_entity_pred) == len(train_entity_true)\n",
    "            assert len(train_relation_pred) == len(train_relation_true)\n",
    "            \n",
    "        # evaluate & save checkpoint\n",
    "        print(\"epoch:\", epoch,\"average loss:\", sum(losses) / len(losses))\n",
    "        results = pd.concat([\n",
    "            evaluator.evaluate_results(train_entity_true, train_entity_pred, entity_label_map, entity_classes),\n",
    "            evaluator.evaluate_results(train_relation_true, train_relation_pred, relation_label_map, relation_classes)\n",
    "        ], keys=[\"Entity\", \"Relation\"])\n",
    "        results.to_csv(constants.model_save_path + \"epoch_\" + str(epoch) + \".csv\")\n",
    "        evaluate(spert_model, constants.dev_dataset)\n",
    "        \n",
    "    torch.save(spert_model.state_dict(), constants.model_save_path + \"epoch_\" + str(constants.epochs-1) + \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "based-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(spert_model, sentences):\n",
    "    for sentence in sentences:\n",
    "        word_list = sentence.split()\n",
    "        words = []\n",
    "        token_ids = []\n",
    "        # transform a sentence to a document for prediction\n",
    "        for word in word_list:\n",
    "            token_id = tokenizer(word)[\"input_ids\"][1:-1]\n",
    "            for tid in token_id:\n",
    "                words.append(word)\n",
    "                token_ids.append(tid)\n",
    "        data_frame = pd.DataFrame()\n",
    "        data_frame[\"words\"] = words\n",
    "        data_frame[\"token_ids\"] = token_ids\n",
    "        data_frame[\"entity_embedding\"] = 0\n",
    "        data_frame[\"sentence_embedding\"] = 0 # for internal datasets\n",
    "        doc = {\"data_frame\": data_frame,\n",
    "            \"entity_position\": {}, # Suppose to appear in non-overlapping dataset\n",
    "            \"entities\": {}, # Suppose to appear in overlapping dataset\n",
    "            \"relations\": {}}\n",
    "        # predict\n",
    "        inputs, infos = input_generator.doc_to_input(doc, device, \n",
    "                                                     is_training=False, \n",
    "                                                     max_span_size=constants.max_span_size)\n",
    "        outputs = spert_model(**inputs, is_training=False)\n",
    "        pred_entity_span = outputs[\"entity\"][\"span\"]\n",
    "        pred_relation_span = [] if outputs[\"relation\"] is None else outputs[\"relation\"][\"span\"]\n",
    "        # print result\n",
    "        tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "        print(\"Sentence:\", sentence)\n",
    "        print(\"Entities: (\", len(pred_entity_span), \")\")\n",
    "        for begin, end, entity_type in pred_entity_span:\n",
    "            print(entity_label_map[entity_type], \"|\", \" \".join(tokens[begin:end]))\n",
    "        print(\"Relations: (\", len(pred_relation_span), \")\")\n",
    "        for e1, e2, relation_type in pred_relation_span:\n",
    "            print(relation_label_map[relation_type], \"|\", \n",
    "                  \" \".join(tokens[e1[0]:e1[1]]), \"|\", \n",
    "                  \" \".join(tokens[e2[0]:e2[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dangerous-error",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing SpERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing SpERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SpERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SpERT were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['relation_classifier.weight', 'relation_classifier.bias', 'entity_classifier.weight', 'entity_classifier.bias', 'width_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Train epoch 0: 100%|█████████████████████████████████████████████████████████████████| 910/910 [01:30<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 average loss: 0.5193515306481948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:42<00:00,  5.79it/s]\n",
      "Train epoch 1:   0%|▏                                                                  | 2/910 [00:00<01:25, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.478261  0.097923     0.162562    337.0\n",
      "                 I-Peop        0.095238  0.008889     0.016260    225.0\n",
      "                 I-Org         0.000000  0.000000     0.000000    190.0\n",
      "                 I-Other       0.000000  0.000000     0.000000    125.0\n",
      "                 macro         0.143375  0.026703     0.044705      NaN\n",
      "                 micro         0.376344  0.039909     0.072165      NaN\n",
      "Entity embedding I-Loc         0.942857  0.143167     0.248588    461.0\n",
      "                 I-Peop        1.000000  0.050549     0.096234    455.0\n",
      "                 I-Org         0.500000  0.002320     0.004619    431.0\n",
      "                 I-Other       1.000000  0.003676     0.007326    272.0\n",
      "                 macro         0.860714  0.049928     0.089192      NaN\n",
      "                 micro         0.947917  0.056208     0.106122      NaN\n",
      "Loose relation   Kill          0.500000  0.055556     0.100000     18.0\n",
      "                 Located_In    0.000000  0.000000     0.000000     67.0\n",
      "                 OrgBased_In   0.000000  0.000000     0.000000    106.0\n",
      "                 Live_In       0.000000  0.000000     0.000000     79.0\n",
      "                 Work_For      0.000000  0.000000     0.000000     83.0\n",
      "                 macro         0.100000  0.011111     0.020000      NaN\n",
      "                 micro         0.058824  0.002833     0.005405      NaN\n",
      "Strict relation  Kill          0.000000  0.000000     0.000000     18.0\n",
      "                 Located_In    0.000000  0.000000     0.000000     67.0\n",
      "                 OrgBased_In   0.000000  0.000000     0.000000    106.0\n",
      "                 Live_In       0.000000  0.000000     0.000000     79.0\n",
      "                 Work_For      0.000000  0.000000     0.000000     83.0\n",
      "                 macro         0.000000  0.000000     0.000000      NaN\n",
      "                 micro         0.000000  0.000000     0.000000      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1: 100%|█████████████████████████████████████████████████████████████████| 910/910 [01:27<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 average loss: 0.2645391725249343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:42<00:00,  5.73it/s]\n",
      "Train epoch 2:   0%|                                                                   | 1/910 [00:00<01:39,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.631313  0.370920     0.467290    337.0\n",
      "                 I-Peop        0.526718  0.306667     0.387640    225.0\n",
      "                 I-Org         0.549296  0.205263     0.298851    190.0\n",
      "                 I-Other       0.185185  0.040000     0.065789    125.0\n",
      "                 macro         0.473128  0.230712     0.304893      NaN\n",
      "                 micro         0.557377  0.271380     0.365031      NaN\n",
      "Entity embedding I-Loc         0.928910  0.425163     0.583333    461.0\n",
      "                 I-Peop        0.979167  0.413187     0.581144    455.0\n",
      "                 I-Org         0.858824  0.169374     0.282946    431.0\n",
      "                 I-Other       0.906250  0.106618     0.190789    272.0\n",
      "                 macro         0.918288  0.278585     0.409553      NaN\n",
      "                 micro         0.934615  0.300185     0.454418      NaN\n",
      "Loose relation   Kill          0.857143  0.333333     0.480000     18.0\n",
      "                 Located_In    0.282051  0.164179     0.207547     67.0\n",
      "                 OrgBased_In   0.275862  0.075472     0.118519    106.0\n",
      "                 Live_In       0.342105  0.164557     0.222222     79.0\n",
      "                 Work_For      1.000000  0.096386     0.175824     83.0\n",
      "                 macro         0.551432  0.166785     0.240822      NaN\n",
      "                 micro         0.380165  0.130312     0.194093      NaN\n",
      "Strict relation  Kill          0.285714  0.111111     0.160000     18.0\n",
      "                 Located_In    0.170732  0.104478     0.129630     67.0\n",
      "                 OrgBased_In   0.206897  0.056604     0.088889    106.0\n",
      "                 Live_In       0.128205  0.063291     0.084746     79.0\n",
      "                 Work_For      0.200000  0.024096     0.043011     83.0\n",
      "                 macro         0.198310  0.071916     0.101255      NaN\n",
      "                 micro         0.174603  0.062323     0.091858      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 2: 100%|█████████████████████████████████████████████████████████████████| 910/910 [01:27<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 average loss: 0.20442946389481262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:40<00:00,  5.94it/s]\n",
      "Train epoch 3:   0%|                                                                           | 0/910 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.716763  0.367953     0.486275    337.0\n",
      "                 I-Peop        0.568966  0.293333     0.387097    225.0\n",
      "                 I-Org         0.554054  0.215789     0.310606    190.0\n",
      "                 I-Other       0.400000  0.064000     0.110345    125.0\n",
      "                 macro         0.559946  0.235269     0.323581      NaN\n",
      "                 micro         0.624021  0.272520     0.379365      NaN\n",
      "Entity embedding I-Loc         0.940217  0.375271     0.536434    461.0\n",
      "                 I-Peop        0.968553  0.338462     0.501629    455.0\n",
      "                 I-Org         0.868132  0.183295     0.302682    431.0\n",
      "                 I-Other       0.880000  0.080882     0.148148    272.0\n",
      "                 macro         0.914226  0.244477     0.372223      NaN\n",
      "                 micro         0.932462  0.264361     0.411935      NaN\n",
      "Loose relation   Kill          0.875000  0.388889     0.538462     18.0\n",
      "                 Located_In    0.280000  0.104478     0.152174     67.0\n",
      "                 OrgBased_In   0.238095  0.047170     0.078740    106.0\n",
      "                 Live_In       0.230769  0.113924     0.152542     79.0\n",
      "                 Work_For      0.846154  0.132530     0.229167     83.0\n",
      "                 macro         0.494004  0.157398     0.230217      NaN\n",
      "                 micro         0.367925  0.110482     0.169935      NaN\n",
      "Strict relation  Kill          0.250000  0.111111     0.153846     18.0\n",
      "                 Located_In    0.200000  0.074627     0.108696     67.0\n",
      "                 OrgBased_In   0.238095  0.047170     0.078740    106.0\n",
      "                 Live_In       0.051282  0.025316     0.033898     79.0\n",
      "                 Work_For      0.285714  0.048193     0.082474     83.0\n",
      "                 macro         0.205018  0.061283     0.091531      NaN\n",
      "                 micro         0.168224  0.050992     0.078261      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 3: 100%|█████████████████████████████████████████████████████████████████| 910/910 [01:28<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 average loss: 0.1780352834612131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:41<00:00,  5.85it/s]\n",
      "Train epoch 4:   0%|                                                                   | 1/910 [00:00<02:07,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.704036  0.465875     0.560714    337.0\n",
      "                 I-Peop        0.607692  0.351111     0.445070    225.0\n",
      "                 I-Org         0.479167  0.242105     0.321678    190.0\n",
      "                 I-Other       0.172414  0.040000     0.064935    125.0\n",
      "                 macro         0.490827  0.274773     0.348100      NaN\n",
      "                 micro         0.600418  0.327252     0.423616      NaN\n",
      "Entity embedding I-Loc         0.922131  0.488069     0.638298    461.0\n",
      "                 I-Peop        0.969388  0.417582     0.583717    455.0\n",
      "                 I-Org         0.775000  0.215777     0.337568    431.0\n",
      "                 I-Other       0.911765  0.113971     0.202614    272.0\n",
      "                 macro         0.894571  0.308850     0.440549      NaN\n",
      "                 micro         0.907407  0.332922     0.487122      NaN\n",
      "Loose relation   Kill          0.888889  0.444444     0.592593     18.0\n",
      "                 Located_In    0.327273  0.268657     0.295082     67.0\n",
      "                 OrgBased_In   0.326087  0.141509     0.197368    106.0\n",
      "                 Live_In       0.169492  0.126582     0.144928     79.0\n",
      "                 Work_For      0.941176  0.192771     0.320000     83.0\n",
      "                 macro         0.530583  0.234793     0.309994      NaN\n",
      "                 micro         0.360215  0.189802     0.248609      NaN\n",
      "Strict relation  Kill          0.222222  0.111111     0.148148     18.0\n",
      "                 Located_In    0.175439  0.149254     0.161290     67.0\n",
      "                 OrgBased_In   0.195652  0.084906     0.118421    106.0\n",
      "                 Live_In       0.066667  0.050633     0.057554     79.0\n",
      "                 Work_For      0.136364  0.036145     0.057143     83.0\n",
      "                 macro         0.159269  0.086410     0.108511      NaN\n",
      "                 micro         0.144330  0.079320     0.102377      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 4: 100%|█████████████████████████████████████████████████████████████████| 910/910 [01:29<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 average loss: 0.1645143508133325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:42<00:00,  5.78it/s]\n",
      "Train epoch 5:   0%|                                                                   | 1/910 [00:00<01:39,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.677824  0.480712     0.562500    337.0\n",
      "                 I-Peop        0.688889  0.413333     0.516667    225.0\n",
      "                 I-Org         0.510417  0.257895     0.342657    190.0\n",
      "                 I-Other       0.192308  0.040000     0.066225    125.0\n",
      "                 macro         0.517359  0.297985     0.372012      NaN\n",
      "                 micro         0.622984  0.352338     0.450109      NaN\n",
      "Entity embedding I-Loc         0.908397  0.516269     0.658368    461.0\n",
      "                 I-Peop        0.961722  0.441758     0.605422    455.0\n",
      "                 I-Org         0.811475  0.229698     0.358047    431.0\n",
      "                 I-Other       0.870968  0.099265     0.178218    272.0\n",
      "                 macro         0.888141  0.321748     0.450014      NaN\n",
      "                 micro         0.905449  0.348981     0.503790      NaN\n",
      "Loose relation   Kill          0.909091  0.555556     0.689655     18.0\n",
      "                 Located_In    0.396226  0.313433     0.350000     67.0\n",
      "                 OrgBased_In   0.333333  0.132075     0.189189    106.0\n",
      "                 Live_In       0.258621  0.189873     0.218978     79.0\n",
      "                 Work_For      0.888889  0.192771     0.316832     83.0\n",
      "                 macro         0.557232  0.276742     0.352931      NaN\n",
      "                 micro         0.417582  0.215297     0.284112      NaN\n",
      "Strict relation  Kill          0.272727  0.166667     0.206897     18.0\n",
      "                 Located_In    0.264151  0.208955     0.233333     67.0\n",
      "                 OrgBased_In   0.238095  0.094340     0.135135    106.0\n",
      "                 Live_In       0.135593  0.101266     0.115942     79.0\n",
      "                 Work_For      0.150000  0.036145     0.058252     83.0\n",
      "                 macro         0.212113  0.121474     0.149912      NaN\n",
      "                 micro         0.205405  0.107649     0.141264      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 5: 100%|█████████████████████████████████████████████████████████████████| 910/910 [01:28<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 average loss: 0.15387904542692743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:41<00:00,  5.84it/s]\n",
      "Train epoch 6:   0%|                                                                           | 0/910 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.724576  0.507418     0.596859    337.0\n",
      "                 I-Peop        0.668919  0.440000     0.530831    225.0\n",
      "                 I-Org         0.520000  0.273684     0.358621    190.0\n",
      "                 I-Other       0.290323  0.072000     0.115385    125.0\n",
      "                 macro         0.550954  0.323276     0.400424      NaN\n",
      "                 micro         0.642718  0.377423     0.475575      NaN\n",
      "Entity embedding I-Loc         0.906015  0.522777     0.662999    461.0\n",
      "                 I-Peop        0.949367  0.494505     0.650289    455.0\n",
      "                 I-Org         0.807407  0.252900     0.385159    431.0\n",
      "                 I-Other       0.926829  0.139706     0.242812    272.0\n",
      "                 macro         0.897405  0.352472     0.485315      NaN\n",
      "                 micro         0.902798  0.378629     0.533507      NaN\n",
      "Loose relation   Kill          1.000000  0.611111     0.758621     18.0\n",
      "                 Located_In    0.500000  0.268657     0.349515     67.0\n",
      "                 OrgBased_In   0.361702  0.160377     0.222222    106.0\n",
      "                 Live_In       0.240506  0.240506     0.240506     79.0\n",
      "                 Work_For      0.826087  0.228916     0.358491     83.0\n",
      "                 macro         0.585659  0.301913     0.385871      NaN\n",
      "                 micro         0.428571  0.237960     0.306011      NaN\n",
      "Strict relation  Kill          0.363636  0.222222     0.275862     18.0\n",
      "                 Located_In    0.388889  0.208955     0.271845     67.0\n",
      "                 OrgBased_In   0.212766  0.094340     0.130719    106.0\n",
      "                 Live_In       0.151899  0.151899     0.151899     79.0\n",
      "                 Work_For      0.291667  0.084337     0.130841     83.0\n",
      "                 macro         0.281771  0.152351     0.192233      NaN\n",
      "                 micro         0.238579  0.133144     0.170909      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 6: 100%|█████████████████████████████████████████████████████████████████| 910/910 [01:28<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 average loss: 0.1480091215367173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:42<00:00,  5.68it/s]\n",
      "Train epoch 7:   0%|                                                                           | 0/910 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.700855  0.486647     0.574431    337.0\n",
      "                 I-Peop        0.628272  0.533333     0.576923    225.0\n",
      "                 I-Org         0.510870  0.247368     0.333333    190.0\n",
      "                 I-Other       0.233333  0.056000     0.090323    125.0\n",
      "                 macro         0.518332  0.330837     0.393752      NaN\n",
      "                 micro         0.617916  0.385405     0.474719      NaN\n",
      "Entity embedding I-Loc         0.901141  0.514100     0.654696    461.0\n",
      "                 I-Peop        0.925806  0.630769     0.750327    455.0\n",
      "                 I-Org         0.838983  0.229698     0.360656    431.0\n",
      "                 I-Other       0.842105  0.117647     0.206452    272.0\n",
      "                 macro         0.877009  0.373054     0.493033      NaN\n",
      "                 micro         0.898491  0.404571     0.557922      NaN\n",
      "Loose relation   Kill          0.909091  0.555556     0.689655     18.0\n",
      "                 Located_In    0.472222  0.253731     0.330097     67.0\n",
      "                 OrgBased_In   0.264151  0.132075     0.176101    106.0\n",
      "                 Live_In       0.275000  0.278481     0.276730     79.0\n",
      "                 Work_For      0.666667  0.337349     0.448000     83.0\n",
      "                 macro         0.517426  0.311439     0.384116      NaN\n",
      "                 micro         0.409910  0.257790     0.316522      NaN\n",
      "Strict relation  Kill          0.545455  0.333333     0.413793     18.0\n",
      "                 Located_In    0.305556  0.164179     0.213592     67.0\n",
      "                 OrgBased_In   0.150943  0.075472     0.100629    106.0\n",
      "                 Live_In       0.158537  0.164557     0.161491     79.0\n",
      "                 Work_For      0.204545  0.108434     0.141732     83.0\n",
      "                 macro         0.273007  0.169195     0.206247      NaN\n",
      "                 micro         0.207965  0.133144     0.162349      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 7: 100%|█████████████████████████████████████████████████████████████████| 910/910 [01:26<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 average loss: 0.14526586620607873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:42<00:00,  5.76it/s]\n",
      "Train epoch 8:   0%|                                                                   | 1/910 [00:00<01:53,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.713080  0.501484     0.588850    337.0\n",
      "                 I-Peop        0.679245  0.480000     0.562500    225.0\n",
      "                 I-Org         0.505376  0.247368     0.332155    190.0\n",
      "                 I-Other       0.366667  0.088000     0.141935    125.0\n",
      "                 macro         0.566092  0.329213     0.406360      NaN\n",
      "                 micro         0.645472  0.381984     0.479943      NaN\n",
      "Entity embedding I-Loc         0.913725  0.505423     0.650838    461.0\n",
      "                 I-Peop        0.946154  0.540659     0.688112    455.0\n",
      "                 I-Org         0.813008  0.232019     0.361011    431.0\n",
      "                 I-Other       0.913043  0.154412     0.264151    272.0\n",
      "                 macro         0.896483  0.358128     0.491028      NaN\n",
      "                 micro         0.907895  0.383570     0.539297      NaN\n",
      "Loose relation   Kill          1.000000  0.555556     0.714286     18.0\n",
      "                 Located_In    0.439024  0.268657     0.333333     67.0\n",
      "                 OrgBased_In   0.237288  0.132075     0.169697    106.0\n",
      "                 Live_In       0.236842  0.227848     0.232258     79.0\n",
      "                 Work_For      0.700000  0.253012     0.371681     83.0\n",
      "                 macro         0.522631  0.287430     0.364251      NaN\n",
      "                 micro         0.375000  0.229462     0.284710      NaN\n",
      "Strict relation  Kill          0.600000  0.333333     0.428571     18.0\n",
      "                 Located_In    0.317073  0.194030     0.240741     67.0\n",
      "                 OrgBased_In   0.152542  0.084906     0.109091    106.0\n",
      "                 Live_In       0.144737  0.139241     0.141935     79.0\n",
      "                 Work_For      0.322581  0.120482     0.175439     83.0\n",
      "                 macro         0.307387  0.174398     0.219155      NaN\n",
      "                 micro         0.225806  0.138810     0.171930      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 8: 100%|█████████████████████████████████████████████████████████████████| 910/910 [01:28<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 average loss: 0.13576528225605797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:41<00:00,  5.88it/s]\n",
      "Train epoch 9:   0%|                                                                           | 0/910 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.716049  0.516320     0.600000    337.0\n",
      "                 I-Peop        0.679012  0.488889     0.568475    225.0\n",
      "                 I-Org         0.595506  0.278947     0.379928    190.0\n",
      "                 I-Other       0.206897  0.048000     0.077922    125.0\n",
      "                 macro         0.549366  0.333039     0.406581      NaN\n",
      "                 micro         0.655832  0.391106     0.490000      NaN\n",
      "Entity embedding I-Loc         0.898551  0.537961     0.672999    461.0\n",
      "                 I-Peop        0.954717  0.556044     0.702778    455.0\n",
      "                 I-Org         0.834711  0.234339     0.365942    431.0\n",
      "                 I-Other       0.878049  0.132353     0.230032    272.0\n",
      "                 macro         0.891507  0.365174     0.492938      NaN\n",
      "                 micro         0.907539  0.394070     0.549526      NaN\n",
      "Loose relation   Kill          1.000000  0.500000     0.666667     18.0\n",
      "                 Located_In    0.476190  0.298507     0.366972     67.0\n",
      "                 OrgBased_In   0.390244  0.150943     0.217687    106.0\n",
      "                 Live_In       0.255814  0.278481     0.266667     79.0\n",
      "                 Work_For      0.609756  0.301205     0.403226     83.0\n",
      "                 macro         0.546401  0.305827     0.384244      NaN\n",
      "                 micro         0.420091  0.260623     0.321678      NaN\n",
      "Strict relation  Kill          0.444444  0.222222     0.296296     18.0\n",
      "                 Located_In    0.357143  0.223881     0.275229     67.0\n",
      "                 OrgBased_In   0.268293  0.103774     0.149660    106.0\n",
      "                 Live_In       0.133333  0.151899     0.142012     79.0\n",
      "                 Work_For      0.302326  0.156627     0.206349     83.0\n",
      "                 macro         0.301108  0.171680     0.213909      NaN\n",
      "                 micro         0.244444  0.155807     0.190311      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 9: 100%|█████████████████████████████████████████████████████████████████| 910/910 [01:26<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 average loss: 0.13334999369498302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:40<00:00,  6.03it/s]\n",
      "Train epoch 10:   0%|▏                                                                 | 2/910 [00:00<01:25, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.754098  0.545994     0.633391    337.0\n",
      "                 I-Peop        0.655738  0.533333     0.588235    225.0\n",
      "                 I-Org         0.578947  0.289474     0.385965    190.0\n",
      "                 I-Other       0.322581  0.080000     0.128205    125.0\n",
      "                 macro         0.577841  0.362200     0.433949      NaN\n",
      "                 micro         0.667269  0.420753     0.516084      NaN\n",
      "Entity embedding I-Loc         0.901060  0.553145     0.685484    461.0\n",
      "                 I-Peop        0.956229  0.624176     0.755319    455.0\n",
      "                 I-Org         0.850394  0.250580     0.387097    431.0\n",
      "                 I-Other       0.906977  0.143382     0.247619    272.0\n",
      "                 macro         0.903665  0.392821     0.518880      NaN\n",
      "                 micro         0.914667  0.423718     0.579147      NaN\n",
      "Loose relation   Kill          1.000000  0.500000     0.666667     18.0\n",
      "                 Located_In    0.488372  0.313433     0.381818     67.0\n",
      "                 OrgBased_In   0.348837  0.141509     0.201342    106.0\n",
      "                 Live_In       0.277108  0.291139     0.283951     79.0\n",
      "                 Work_For      0.658537  0.325301     0.435484     83.0\n",
      "                 macro         0.554571  0.314277     0.393852      NaN\n",
      "                 micro         0.433790  0.269122     0.332168      NaN\n",
      "Strict relation  Kill          0.555556  0.277778     0.370370     18.0\n",
      "                 Located_In    0.348837  0.223881     0.272727     67.0\n",
      "                 OrgBased_In   0.232558  0.094340     0.134228    106.0\n",
      "                 Live_In       0.186047  0.202532     0.193939     79.0\n",
      "                 Work_For      0.302326  0.156627     0.206349     83.0\n",
      "                 macro         0.325065  0.191031     0.235523      NaN\n",
      "                 micro         0.263393  0.167139     0.204506      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 10: 100%|████████████████████████████████████████████████████████████████| 910/910 [01:24<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 average loss: 0.13376026887262424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:41<00:00,  5.91it/s]\n",
      "Train epoch 11:   0%|▏                                                                 | 2/910 [00:00<01:25, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.764444  0.510386     0.612100    337.0\n",
      "                 I-Peop        0.641176  0.484444     0.551899    225.0\n",
      "                 I-Org         0.565217  0.273684     0.368794    190.0\n",
      "                 I-Other       0.368421  0.056000     0.097222    125.0\n",
      "                 macro         0.584815  0.331129     0.407504      NaN\n",
      "                 micro         0.671937  0.387685     0.491685      NaN\n",
      "Entity embedding I-Loc         0.921569  0.509761     0.656425    461.0\n",
      "                 I-Peop        0.933099  0.582418     0.717185    455.0\n",
      "                 I-Org         0.827869  0.234339     0.365280    431.0\n",
      "                 I-Other       0.884615  0.084559     0.154362    272.0\n",
      "                 macro         0.891788  0.352769     0.473313      NaN\n",
      "                 micro         0.908297  0.385423     0.541197      NaN\n",
      "Loose relation   Kill          1.000000  0.500000     0.666667     18.0\n",
      "                 Located_In    0.514286  0.268657     0.352941     67.0\n",
      "                 OrgBased_In   0.283019  0.141509     0.188679    106.0\n",
      "                 Live_In       0.253012  0.265823     0.259259     79.0\n",
      "                 Work_For      0.750000  0.289157     0.417391     83.0\n",
      "                 macro         0.560063  0.293029     0.376988      NaN\n",
      "                 micro         0.410377  0.246459     0.307965      NaN\n",
      "Strict relation  Kill          0.555556  0.277778     0.370370     18.0\n",
      "                 Located_In    0.371429  0.194030     0.254902     67.0\n",
      "                 OrgBased_In   0.226415  0.113208     0.150943    106.0\n",
      "                 Live_In       0.141176  0.151899     0.146341     79.0\n",
      "                 Work_For      0.363636  0.144578     0.206897     83.0\n",
      "                 macro         0.331642  0.176298     0.225891      NaN\n",
      "                 micro         0.251163  0.152975     0.190141      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 11: 100%|████████████████████████████████████████████████████████████████| 910/910 [01:27<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 average loss: 0.1290410793683195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:40<00:00,  5.99it/s]\n",
      "Train epoch 12:   0%|                                                                  | 1/910 [00:00<01:39,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.784404  0.507418     0.616216    337.0\n",
      "                 I-Peop        0.666667  0.497778     0.569975    225.0\n",
      "                 I-Org         0.530000  0.278947     0.365517    190.0\n",
      "                 I-Other       0.461538  0.096000     0.158940    125.0\n",
      "                 macro         0.610652  0.345036     0.427662      NaN\n",
      "                 micro         0.679688  0.396807     0.501080      NaN\n",
      "Entity embedding I-Loc         0.935484  0.503254     0.654443    461.0\n",
      "                 I-Peop        0.935484  0.573626     0.711172    455.0\n",
      "                 I-Org         0.801471  0.252900     0.384480    431.0\n",
      "                 I-Other       0.900000  0.132353     0.230769    272.0\n",
      "                 macro         0.893110  0.365533     0.495216      NaN\n",
      "                 micro         0.907539  0.394070     0.549526      NaN\n",
      "Loose relation   Kill          1.000000  0.555556     0.714286     18.0\n",
      "                 Located_In    0.527778  0.283582     0.368932     67.0\n",
      "                 OrgBased_In   0.312500  0.141509     0.194805    106.0\n",
      "                 Live_In       0.281250  0.227848     0.251748     79.0\n",
      "                 Work_For      0.658537  0.325301     0.435484     83.0\n",
      "                 macro         0.556013  0.306759     0.393051      NaN\n",
      "                 micro         0.447236  0.252125     0.322464      NaN\n",
      "Strict relation  Kill          0.600000  0.333333     0.428571     18.0\n",
      "                 Located_In    0.416667  0.223881     0.291262     67.0\n",
      "                 OrgBased_In   0.187500  0.084906     0.116883    106.0\n",
      "                 Live_In       0.169231  0.139241     0.152778     79.0\n",
      "                 Work_For      0.302326  0.156627     0.206349     83.0\n",
      "                 macro         0.335145  0.187597     0.239169      NaN\n",
      "                 micro         0.267327  0.152975     0.194595      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 12: 100%|████████████████████████████████████████████████████████████████| 910/910 [01:28<00:00, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 average loss: 0.1265842727180775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:41<00:00,  5.83it/s]\n",
      "Train epoch 13:   0%|                                                                  | 1/910 [00:00<01:39,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.804762  0.501484     0.617916    337.0\n",
      "                 I-Peop        0.791045  0.471111     0.590529    225.0\n",
      "                 I-Org         0.593023  0.268421     0.369565    190.0\n",
      "                 I-Other       0.448276  0.104000     0.168831    125.0\n",
      "                 macro         0.659276  0.336254     0.436710      NaN\n",
      "                 micro         0.738562  0.386545     0.507485      NaN\n",
      "Entity embedding I-Loc         0.921811  0.485900     0.636364    461.0\n",
      "                 I-Peop        0.974249  0.498901     0.659884    455.0\n",
      "                 I-Org         0.820513  0.222738     0.350365    431.0\n",
      "                 I-Other       0.928571  0.143382     0.248408    272.0\n",
      "                 macro         0.911286  0.337730     0.473755      NaN\n",
      "                 micro         0.922835  0.361952     0.519965      NaN\n",
      "Loose relation   Kill          1.000000  0.555556     0.714286     18.0\n",
      "                 Located_In    0.500000  0.238806     0.323232     67.0\n",
      "                 OrgBased_In   0.382353  0.122642     0.185714    106.0\n",
      "                 Live_In       0.279070  0.151899     0.196721     79.0\n",
      "                 Work_For      0.571429  0.240964     0.338983     83.0\n",
      "                 macro         0.546570  0.261973     0.351787      NaN\n",
      "                 micro         0.461039  0.201133     0.280079      NaN\n",
      "Strict relation  Kill          0.800000  0.444444     0.571429     18.0\n",
      "                 Located_In    0.406250  0.194030     0.262626     67.0\n",
      "                 OrgBased_In   0.264706  0.084906     0.128571    106.0\n",
      "                 Live_In       0.186047  0.101266     0.131148     79.0\n",
      "                 Work_For      0.250000  0.108434     0.151261     83.0\n",
      "                 macro         0.381400  0.186616     0.249007      NaN\n",
      "                 micro         0.303226  0.133144     0.185039      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 13: 100%|████████████████████████████████████████████████████████████████| 910/910 [01:29<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 average loss: 0.1279320717574312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:42<00:00,  5.71it/s]\n",
      "Train epoch 14:   0%|                                                                  | 1/910 [00:00<01:39,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.764192  0.519288     0.618375    337.0\n",
      "                 I-Peop        0.697674  0.533333     0.604534    225.0\n",
      "                 I-Org         0.600000  0.284211     0.385714    190.0\n",
      "                 I-Other       0.464286  0.104000     0.169935    125.0\n",
      "                 macro         0.631538  0.360208     0.444639      NaN\n",
      "                 micro         0.697495  0.412771     0.518625      NaN\n",
      "Entity embedding I-Loc         0.909774  0.524946     0.665750    461.0\n",
      "                 I-Peop        0.938567  0.604396     0.735294    455.0\n",
      "                 I-Org         0.851240  0.238979     0.373188    431.0\n",
      "                 I-Other       0.928571  0.143382     0.248408    272.0\n",
      "                 macro         0.907038  0.377926     0.505660      NaN\n",
      "                 micro         0.912742  0.407041     0.563007      NaN\n",
      "Loose relation   Kill          1.000000  0.611111     0.758621     18.0\n",
      "                 Located_In    0.514286  0.268657     0.352941     67.0\n",
      "                 OrgBased_In   0.291667  0.132075     0.181818    106.0\n",
      "                 Live_In       0.246377  0.215190     0.229730     79.0\n",
      "                 Work_For      0.627907  0.325301     0.428571     83.0\n",
      "                 macro         0.536047  0.310467     0.390336      NaN\n",
      "                 micro         0.422330  0.246459     0.311270      NaN\n",
      "Strict relation  Kill          0.545455  0.333333     0.413793     18.0\n",
      "                 Located_In    0.400000  0.208955     0.274510     67.0\n",
      "                 OrgBased_In   0.229167  0.103774     0.142857    106.0\n",
      "                 Live_In       0.128571  0.113924     0.120805     79.0\n",
      "                 Work_For      0.333333  0.180723     0.234375     83.0\n",
      "                 macro         0.327305  0.188142     0.237268      NaN\n",
      "                 micro         0.263158  0.155807     0.195730      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 14: 100%|████████████████████████████████████████████████████████████████| 910/910 [01:28<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 average loss: 0.12389161139828982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:42<00:00,  5.78it/s]\n",
      "Train epoch 15:   0%|                                                                  | 1/910 [00:00<01:39,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.738776  0.537092     0.621993    337.0\n",
      "                 I-Peop        0.708609  0.475556     0.569149    225.0\n",
      "                 I-Org         0.509615  0.278947     0.360544    190.0\n",
      "                 I-Other       0.357143  0.080000     0.130719    125.0\n",
      "                 macro         0.578536  0.342899     0.420601      NaN\n",
      "                 micro         0.664773  0.400228     0.499644      NaN\n",
      "Entity embedding I-Loc         0.906137  0.544469     0.680217    461.0\n",
      "                 I-Peop        0.960938  0.540659     0.691983    455.0\n",
      "                 I-Org         0.802721  0.273782     0.408304    431.0\n",
      "                 I-Other       0.900000  0.132353     0.230769    272.0\n",
      "                 macro         0.892449  0.372816     0.502818      NaN\n",
      "                 micro         0.904167  0.402100     0.556648      NaN\n",
      "Loose relation   Kill          1.000000  0.611111     0.758621     18.0\n",
      "                 Located_In    0.538462  0.313433     0.396226     67.0\n",
      "                 OrgBased_In   0.346154  0.169811     0.227848    106.0\n",
      "                 Live_In       0.357143  0.253165     0.296296     79.0\n",
      "                 Work_For      0.630435  0.349398     0.449612     83.0\n",
      "                 macro         0.574439  0.339383     0.425721      NaN\n",
      "                 micro         0.485294  0.280453     0.355476      NaN\n",
      "Strict relation  Kill          0.636364  0.388889     0.482759     18.0\n",
      "                 Located_In    0.410256  0.238806     0.301887     67.0\n",
      "                 OrgBased_In   0.192308  0.094340     0.126582    106.0\n",
      "                 Live_In       0.160714  0.113924     0.133333     79.0\n",
      "                 Work_For      0.229167  0.132530     0.167939     83.0\n",
      "                 macro         0.325762  0.193698     0.242500      NaN\n",
      "                 micro         0.257282  0.150142     0.189624      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 15: 100%|████████████████████████████████████████████████████████████████| 910/910 [01:28<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 average loss: 0.12179762400318306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:41<00:00,  5.85it/s]\n",
      "Train epoch 16:   0%|                                                                  | 1/910 [00:00<01:53,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.756303  0.534125     0.626087    337.0\n",
      "                 I-Peop        0.751773  0.471111     0.579235    225.0\n",
      "                 I-Org         0.622222  0.294737     0.400000    190.0\n",
      "                 I-Other       0.379310  0.088000     0.142857    125.0\n",
      "                 macro         0.627402  0.346993     0.437045      NaN\n",
      "                 micro         0.708835  0.402509     0.513455      NaN\n",
      "Entity embedding I-Loc         0.898917  0.540130     0.674797    461.0\n",
      "                 I-Peop        0.974576  0.505495     0.665702    455.0\n",
      "                 I-Org         0.829457  0.248260     0.382143    431.0\n",
      "                 I-Other       0.928571  0.143382     0.248408    272.0\n",
      "                 macro         0.907881  0.359317     0.492762      NaN\n",
      "                 micro         0.913743  0.386041     0.542770      NaN\n",
      "Loose relation   Kill          1.000000  0.611111     0.758621     18.0\n",
      "                 Located_In    0.555556  0.298507     0.388350     67.0\n",
      "                 OrgBased_In   0.404762  0.160377     0.229730    106.0\n",
      "                 Live_In       0.352941  0.227848     0.276923     79.0\n",
      "                 Work_For      0.666667  0.240964     0.353982     83.0\n",
      "                 macro         0.595985  0.307762     0.401521      NaN\n",
      "                 micro         0.505882  0.243626     0.328872      NaN\n",
      "Strict relation  Kill          0.545455  0.333333     0.413793     18.0\n",
      "                 Located_In    0.416667  0.223881     0.291262     67.0\n",
      "                 OrgBased_In   0.285714  0.113208     0.162162    106.0\n",
      "                 Live_In       0.176471  0.113924     0.138462     79.0\n",
      "                 Work_For      0.375000  0.144578     0.208696     83.0\n",
      "                 macro         0.359861  0.185785     0.242875      NaN\n",
      "                 micro         0.313953  0.152975     0.205714      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 16: 100%|████████████████████████████████████████████████████████████████| 910/910 [01:28<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 average loss: 0.11929864809940477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:44<00:00,  5.49it/s]\n",
      "Train epoch 17:   0%|                                                                  | 1/910 [00:00<01:39,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.742616  0.522255     0.613240    337.0\n",
      "                 I-Peop        0.740000  0.493333     0.592000    225.0\n",
      "                 I-Org         0.529412  0.284211     0.369863    190.0\n",
      "                 I-Other       0.433333  0.104000     0.167742    125.0\n",
      "                 macro         0.611340  0.350950     0.435711      NaN\n",
      "                 micro         0.682081  0.403649     0.507163      NaN\n",
      "Entity embedding I-Loc         0.903346  0.527115     0.665753    461.0\n",
      "                 I-Peop        0.964844  0.542857     0.694796    455.0\n",
      "                 I-Org         0.763158  0.269142     0.397942    431.0\n",
      "                 I-Other       0.901961  0.169118     0.284830    272.0\n",
      "                 macro         0.883327  0.377058     0.510830      NaN\n",
      "                 micro         0.895604  0.402718     0.555603      NaN\n",
      "Loose relation   Kill          0.909091  0.555556     0.689655     18.0\n",
      "                 Located_In    0.558824  0.283582     0.376238     67.0\n",
      "                 OrgBased_In   0.302326  0.122642     0.174497    106.0\n",
      "                 Live_In       0.306452  0.240506     0.269504     79.0\n",
      "                 Work_For      0.690476  0.349398     0.464000     83.0\n",
      "                 macro         0.553434  0.310337     0.394779      NaN\n",
      "                 micro         0.468750  0.254958     0.330275      NaN\n",
      "Strict relation  Kill          0.727273  0.444444     0.551724     18.0\n",
      "                 Located_In    0.411765  0.208955     0.277228     67.0\n",
      "                 OrgBased_In   0.232558  0.094340     0.134228    106.0\n",
      "                 Live_In       0.156250  0.126582     0.139860     79.0\n",
      "                 Work_For      0.279070  0.144578     0.190476     83.0\n",
      "                 macro         0.361383  0.203780     0.258703      NaN\n",
      "                 micro         0.276923  0.152975     0.197080      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 17: 100%|████████████████████████████████████████████████████████████████| 910/910 [01:30<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 average loss: 0.12144089000975038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:43<00:00,  5.61it/s]\n",
      "Train epoch 18:   0%|                                                                          | 0/910 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.759336  0.543027     0.633218    337.0\n",
      "                 I-Peop        0.689024  0.502222     0.580977    225.0\n",
      "                 I-Org         0.500000  0.278947     0.358108    190.0\n",
      "                 I-Other       0.411765  0.112000     0.176101    125.0\n",
      "                 macro         0.590031  0.359049     0.437101      NaN\n",
      "                 micro         0.666055  0.413911     0.510549      NaN\n",
      "Entity embedding I-Loc         0.899642  0.544469     0.678378    461.0\n",
      "                 I-Peop        0.946043  0.578022     0.717599    455.0\n",
      "                 I-Org         0.797386  0.283063     0.417808    431.0\n",
      "                 I-Other       0.927273  0.187500     0.311927    272.0\n",
      "                 macro         0.892586  0.398263     0.531428      NaN\n",
      "                 micro         0.898039  0.424336     0.576342      NaN\n",
      "Loose relation   Kill          0.857143  0.666667     0.750000     18.0\n",
      "                 Located_In    0.571429  0.298507     0.392157     67.0\n",
      "                 OrgBased_In   0.418605  0.169811     0.241611    106.0\n",
      "                 Live_In       0.300000  0.265823     0.281879     79.0\n",
      "                 Work_For      0.738095  0.373494     0.496000     83.0\n",
      "                 macro         0.577054  0.354860     0.432329      NaN\n",
      "                 micro         0.500000  0.288952     0.366248      NaN\n",
      "Strict relation  Kill          0.500000  0.388889     0.437500     18.0\n",
      "                 Located_In    0.428571  0.223881     0.294118     67.0\n",
      "                 OrgBased_In   0.186047  0.075472     0.107383    106.0\n",
      "                 Live_In       0.166667  0.151899     0.158940     79.0\n",
      "                 Work_For      0.285714  0.144578     0.192000     83.0\n",
      "                 macro         0.313400  0.196944     0.237988      NaN\n",
      "                 micro         0.262136  0.152975     0.193202      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 18: 100%|████████████████████████████████████████████████████████████████| 910/910 [01:25<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 average loss: 0.12062201128279852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:40<00:00,  5.97it/s]\n",
      "Train epoch 19:   0%|                                                                  | 1/910 [00:00<01:39,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.730924  0.540059     0.621160    337.0\n",
      "                 I-Peop        0.711538  0.493333     0.582677    225.0\n",
      "                 I-Org         0.612245  0.315789     0.416667    190.0\n",
      "                 I-Other       0.424242  0.112000     0.177215    125.0\n",
      "                 macro         0.619737  0.365296     0.449430      NaN\n",
      "                 micro         0.684701  0.418472     0.519462      NaN\n",
      "Entity embedding I-Loc         0.903915  0.550976     0.684636    461.0\n",
      "                 I-Peop        0.940959  0.560440     0.702479    455.0\n",
      "                 I-Org         0.818792  0.283063     0.420690    431.0\n",
      "                 I-Other       0.940000  0.172794     0.291925    272.0\n",
      "                 macro         0.900916  0.391818     0.524933      NaN\n",
      "                 micro         0.902796  0.418777     0.572152      NaN\n",
      "Loose relation   Kill          0.916667  0.611111     0.733333     18.0\n",
      "                 Located_In    0.552632  0.313433     0.400000     67.0\n",
      "                 OrgBased_In   0.324324  0.113208     0.167832    106.0\n",
      "                 Live_In       0.344262  0.265823     0.300000     79.0\n",
      "                 Work_For      0.777778  0.337349     0.470588     83.0\n",
      "                 macro         0.583133  0.328185     0.414351      NaN\n",
      "                 micro         0.505435  0.263456     0.346369      NaN\n",
      "Strict relation  Kill          0.416667  0.277778     0.333333     18.0\n",
      "                 Located_In    0.368421  0.208955     0.266667     67.0\n",
      "                 OrgBased_In   0.243243  0.084906     0.125874    106.0\n",
      "                 Live_In       0.190476  0.151899     0.169014     79.0\n",
      "                 Work_For      0.388889  0.168675     0.235294     83.0\n",
      "                 macro         0.321539  0.178442     0.226036      NaN\n",
      "                 micro         0.290323  0.152975     0.200371      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 19: 100%|████████████████████████████████████████████████████████████████| 910/910 [01:26<00:00, 10.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 average loss: 0.12044108577052151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation dev: 100%|████████████████████████████████████████████████████████████████| 243/243 [00:42<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.729412  0.551929     0.628378    337.0\n",
      "                 I-Peop        0.716049  0.515556     0.599483    225.0\n",
      "                 I-Org         0.571429  0.294737     0.388889    190.0\n",
      "                 I-Other       0.323529  0.088000     0.138365    125.0\n",
      "                 macro         0.585105  0.362555     0.438779      NaN\n",
      "                 micro         0.672131  0.420753     0.517532      NaN\n",
      "Entity embedding I-Loc         0.905594  0.561822     0.693440    461.0\n",
      "                 I-Peop        0.948718  0.569231     0.711538    455.0\n",
      "                 I-Org         0.834532  0.269142     0.407018    431.0\n",
      "                 I-Other       0.882353  0.165441     0.278638    272.0\n",
      "                 macro         0.892799  0.391409     0.522659      NaN\n",
      "                 micro         0.906542  0.419395     0.573480      NaN\n",
      "Loose relation   Kill          0.916667  0.611111     0.733333     18.0\n",
      "                 Located_In    0.511628  0.328358     0.400000     67.0\n",
      "                 OrgBased_In   0.411765  0.132075     0.200000    106.0\n",
      "                 Live_In       0.400000  0.253165     0.310078     79.0\n",
      "                 Work_For      0.750000  0.325301     0.453782     83.0\n",
      "                 macro         0.598012  0.330002     0.419438      NaN\n",
      "                 micro         0.537143  0.266289     0.356061      NaN\n",
      "Strict relation  Kill          0.500000  0.333333     0.400000     18.0\n",
      "                 Located_In    0.348837  0.223881     0.272727     67.0\n",
      "                 OrgBased_In   0.264706  0.084906     0.128571    106.0\n",
      "                 Live_In       0.192308  0.126582     0.152672     79.0\n",
      "                 Work_For      0.378378  0.168675     0.233333     83.0\n",
      "                 macro         0.336846  0.187475     0.237461      NaN\n",
      "                 micro         0.303371  0.152975     0.203390      NaN\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "gorgeous-block",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing SpERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing SpERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SpERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SpERT were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['relation_classifier.weight', 'relation_classifier.bias', 'entity_classifier.weight', 'entity_classifier.bias', 'width_embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpERT(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (relation_classifier): Linear(in_features=2354, out_features=5, bias=True)\n",
       "  (entity_classifier): Linear(in_features=1561, out_features=5, bias=True)\n",
       "  (width_embedding): Embedding(100, 25)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained(constants.model_path)\n",
    "spert_model = model.SpERT.from_pretrained(constants.model_path,\n",
    "                                          config=config,\n",
    "                                          # SpERT model parameters\n",
    "                                          relation_types=constants.relation_types, \n",
    "                                          entity_types=constants.entity_types, \n",
    "                                          width_embedding_size=constants.width_embedding_size, \n",
    "                                          prop_drop=constants.prop_drop, \n",
    "                                          freeze_transformer=True, \n",
    "                                          max_pairs=constants.max_pairs, \n",
    "                                          is_overlapping=constants.is_overlapping, \n",
    "                                          relation_filter_threshold=constants.relation_filter_threshold)\n",
    "spert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "reflected-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(constants.model_save_path + \"epoch_\" + str(constants.epochs-1) + \".model\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "subsequent-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To run reference model\n",
    "# state_dict = torch.load(\"../../model/spert/reference/reference_model.bin\")\n",
    "# state_dict[\"relation_classifier.weight\"] = state_dict[\"rel_classifier.weight\"]\n",
    "# state_dict[\"relation_classifier.bias\"] = state_dict[\"rel_classifier.bias\"]\n",
    "# state_dict[\"width_embedding.weight\"] = state_dict[\"size_embeddings.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "primary-briefs",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation test: 100%|███████████████████████████████████████████████████████████████| 288/288 [00:52<00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  fbeta_score  support\n",
      "Entity span      I-Loc         0.685714  0.562061     0.617761    427.0\n",
      "                 I-Peop        0.714286  0.482866     0.576208    321.0\n",
      "                 I-Org         0.666667  0.323232     0.435374    198.0\n",
      "                 I-Other       0.347826  0.120301     0.178771    133.0\n",
      "                 macro         0.603623  0.372115     0.452028      NaN\n",
      "                 micro         0.669958  0.440222     0.531320      NaN\n",
      "Entity embedding I-Loc         0.893827  0.572785     0.698168    632.0\n",
      "                 I-Peop        0.969863  0.516035     0.673644    686.0\n",
      "                 I-Org         0.903448  0.298405     0.448630    439.0\n",
      "                 I-Other       0.820896  0.209125     0.333333    263.0\n",
      "                 macro         0.897008  0.399088     0.538444      NaN\n",
      "                 micro         0.918534  0.446535     0.600933      NaN\n",
      "Loose relation   Kill          0.760000  0.404255     0.527778     47.0\n",
      "                 Located_In    0.444444  0.340426     0.385542     94.0\n",
      "                 OrgBased_In   0.468085  0.209524     0.289474    105.0\n",
      "                 Live_In       0.584906  0.310000     0.405229    100.0\n",
      "                 Work_For      0.642857  0.236842     0.346154     76.0\n",
      "                 macro         0.580058  0.300209     0.390835      NaN\n",
      "                 micro         0.542222  0.289100     0.377125      NaN\n",
      "Strict relation  Kill          0.520000  0.276596     0.361111     47.0\n",
      "                 Located_In    0.347222  0.265957     0.301205     94.0\n",
      "                 OrgBased_In   0.312500  0.142857     0.196078    105.0\n",
      "                 Live_In       0.192982  0.110000     0.140127    100.0\n",
      "                 Work_For      0.166667  0.065789     0.094340     76.0\n",
      "                 macro         0.307874  0.172240     0.218572      NaN\n",
      "                 micro         0.297414  0.163507     0.211009      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "spert_model.load_state_dict(state_dict, strict=False)\n",
    "evaluate(spert_model, constants.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pleasant-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load(constants.model_save_path + \"epoch_\" + str(constants.epochs-1) + \".model\")\n",
    "# state_dict[\"rel_classifier.weight\"] = state_dict[\"relation_classifier.weight\"]\n",
    "# state_dict[\"rel_classifier.bias\"] = state_dict[\"relation_classifier.bias\"]\n",
    "# state_dict[\"size_embeddings.weight\"] = state_dict[\"width_embedding.weight\"]\n",
    "# del state_dict[\"relation_classifier.weight\"]\n",
    "# del state_dict[\"relation_classifier.bias\"]\n",
    "# del state_dict[\"width_embedding.weight\"]\n",
    "# del state_dict[\"bert.embeddings.position_ids\"]\n",
    "# torch.save(state_dict, \"../../model/spert/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "three-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(spert_model, sentences=[\"However, the Rev. Jesse Jackson, a native of South Carolina, joined critics of FEMA's effort.\", \n",
    "#                                 \"International Paper spokeswoman Ann Silvernail said that under French law the company was barred from releasing details pending government approval.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adult-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \" \".join([\"An\", \"art\", \"exhibit\", \"at\", \"the\", \"Hakawati\", \"Theatre\", \"in\", \"Arab\", \"east\", \"Jerusalem\", \"was\", \"a\", \"series\", \"of\", \"portraits\", \"of\", \"Palestinians\", \"killed\", \"in\", \"the\", \"rebellion\", \".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "atomic-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"entities\": [{\"type\": \"Loc\", \"start\": 5, \"end\": 7}, {\"type\": \"Loc\", \"start\": 10, \"end\": 11}, {\"type\": \"Other\", \"start\": 17, \"end\": 18}], \"relations\": [{\"type\": \"Located_In\", \"head\": 0, \"tail\": 1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "about-auction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: An art exhibit at the Hakawati Theatre in Arab east Jerusalem was a series of portraits of Palestinians killed in the rebellion .\n",
      "Entities: ( 1 )\n",
      "I-Loc | Jerusalem\n",
      "Relations: ( 0 )\n"
     ]
    }
   ],
   "source": [
    "predict(spert_model, sentences=[test_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "departmental-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \" \".join([\"PERUGIA\", \",\", \"Italy\", \"(\", \"AP\", \")\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fantastic-vault",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: PERUGIA , Italy ( AP )\n",
      "Entities: ( 2 )\n",
      "I-Org | AP\n",
      "I-Loc | Italy\n",
      "Relations: ( 1 )\n",
      "OrgBased_In | AP | Italy\n"
     ]
    }
   ],
   "source": [
    "predict(spert_model, sentences=[test_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-understanding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

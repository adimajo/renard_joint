{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cardiovascular-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from typing import Optional, Tuple\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "similar-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\\\\parser\")\n",
    "import conll04_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faced-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from transformers.modeling_outputs import ModelOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "governing-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MreOutput(ModelOutput):\n",
    "    \"\"\"\n",
    "    Base class for outputs of token classification models.\n",
    "\n",
    "    Args:\n",
    "        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when ``labels`` is provided) :\n",
    "            Classification loss.\n",
    "        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, max_entities ** 2, num_labels)`):\n",
    "            Classification scores (before SoftMax).\n",
    "        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_hidden_states=True`` is passed or when ``config.output_hidden_states=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
    "            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
    "\n",
    "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n",
    "            sequence_length, sequence_length)`.\n",
    "\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "    \"\"\"\n",
    "\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits: torch.FloatTensor = None\n",
    "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[torch.FloatTensor]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bibliographic-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMre(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_labels,  \n",
    "        model_name = \"bert-base-uncased\"\n",
    "    ):\n",
    "        super(BertForMre, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.bert.train() # Set BERT to training mode\n",
    "        self.dropout = nn.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size * 2, num_labels)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        e1_mask=None,\n",
    "        e2_mask=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=True,\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        \n",
    "        logits = None\n",
    "        if e1_mask is not None and e2_mask is not None:\n",
    "            num_relation = e1_mask.shape[0]\n",
    "            seq_length = e1_mask.shape[1]\n",
    "            sequence_output = torch.stack([sequence_output] * num_relation, dim=1)\n",
    "            \n",
    "            e1_mask = torch.reshape(e1_mask, [-1, num_relation, seq_length, 1])\n",
    "            e1 = torch.mul(sequence_output, e1_mask.float())\n",
    "            e1 = torch.sum(e1, dim=-2) / torch.clamp(torch.sum(e1_mask.float(), dim=-2), min=1.0)\n",
    "            e1 = torch.reshape(e1, [-1, self.bert.config.hidden_size])\n",
    "            \n",
    "            e2_mask = torch.reshape(e2_mask, [-1, num_relation, seq_length, 1])\n",
    "            e2 = torch.mul(sequence_output, e2_mask.float())\n",
    "            e2 = torch.sum(e2, dim=-2) / torch.clamp(torch.sum(e2_mask.float(), dim=-2), min=1.0)\n",
    "            e2 = torch.reshape(e2, [-1, self.bert.config.hidden_size])\n",
    "            \n",
    "            sequence_output = torch.cat([e1, e2], dim=-1)\n",
    "            logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if logits is not None and labels is not None:\n",
    "            # print(logits.type(), labels.type())\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.long().view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:] if logits is not None else outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return MreOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "instrumental-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMre(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "russian-print",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMre(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1536, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sweet-special",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Freeze all layers except for the last classifier layer on top\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.classifier.weight.requires_grad = True\n",
    "model.classifier.bias.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aging-salad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: torch.Size([30522, 768])\n",
      "False\n",
      "size: torch.Size([512, 768])\n",
      "False\n",
      "size: torch.Size([2, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([3072, 768])\n",
      "False\n",
      "size: torch.Size([3072])\n",
      "False\n",
      "size: torch.Size([768, 3072])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([768, 768])\n",
      "False\n",
      "size: torch.Size([768])\n",
      "False\n",
      "size: torch.Size([7, 1536])\n",
      "True\n",
      "size: torch.Size([7])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(\"size:\", param.shape)\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alpine-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_entity_mask(sequence_length, entity_position, relations):\n",
    "    relation_count = len(entity_position) * (len(entity_position) - 1)\n",
    "    e1_mask = torch.zeros((relation_count, sequence_length))\n",
    "    e2_mask = torch.zeros((relation_count, sequence_length))\n",
    "    labels = torch.zeros(relation_count)\n",
    "    i = 0\n",
    "    for e1 in entity_position:\n",
    "        for e2 in entity_position:\n",
    "            if e1 != e2:\n",
    "                l1, h1 = entity_position[e1]\n",
    "                l2, h2 = entity_position[e2]\n",
    "                e1_mask[i, l1:h1] = 1\n",
    "                e2_mask[i, l2:h2] = 1\n",
    "                for relation in relations:\n",
    "                    if relations[relation][\"source\"] == e1 and relations[relation][\"target\"] == e2:\n",
    "                        labels[i] = relations[relation][\"type\"]\n",
    "                i += 1\n",
    "    return e1_mask, e2_mask, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "inside-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generate_entity_mask()\n",
    "docs = conll04_parser.get_docs(\"train\")\n",
    "extracted_doc = conll04_parser.extract_doc(docs[0])\n",
    "assert extracted_doc[\"document\"] == \"1024\"\n",
    "e1_mask, e2_mask, labels = generate_entity_mask(\n",
    "    extracted_doc[\"data_frame\"].shape[0], \n",
    "    extracted_doc[\"entity_position\"], \n",
    "    extracted_doc[\"relations\"]\n",
    ")\n",
    "\n",
    "assert np.array_equal(e1_mask, np.array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., \n",
    "         0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., \n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], \n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., \n",
    "         0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., \n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], \n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., \n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], \n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., \n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., \n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], \n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., \n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], \n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., \n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., \n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))\n",
    "\n",
    "assert np.array_equal(e2_mask, np.array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))\n",
    "\n",
    "assert np.array_equal(labels, np.array([0., 2., 0., 2., 0., 0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "appropriate-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "double-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(\n",
    "    torch.tensor([extracted_doc[\"data_frame\"][\"token_ids\"]]), \n",
    "    e1_mask=e1_mask, \n",
    "    e2_mask=e2_mask, \n",
    "    labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "intimate-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mediterranean-finder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1971, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-ceiling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
